{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import uesgraphs as ug\n",
    "\n",
    "from uesgraphs.examples import e1_example_readme as e1\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uesgraphs.analysis as analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "workspace = e1.workspace_example(\"e14\")\n",
    "\n",
    "dir_ues = os.path.dirname(os.path.dirname(workspace))\n",
    "pinola_json = os.path.join(dir_ues, \"workspace\", \"e11\", \"inputs\",\"test_modelgen\", \"Pinola\", \"nodes.json\")\n",
    "pinola_sim_data = os.path.join(dir_ues,\"uesgraphs\",\"data\",\"Pinola_low_temp_network_inputs.mat\")\n",
    "pinola_sim_data = r\"E:\\rka_lko\\work\\2025_04_analysis\\10042025SeestadtNewSim\\Sim20250409_190504_detailed\\Sim20250409_190504_1\\Results\\Sim20250409_190504_1_inputs.gzip\"\n",
    "pinola_json =r\"E:\\rka_lko\\git\\transurban_seestadt\\dhc_model\\workspace\\transurban_seestadt_uesgraphs.json\"\n",
    "sysm_model = r\"E:\\rka_lko\\git\\transurban_seestadt\\dhc_model\\workspace\\model.json\"\n",
    "if not os.path.exists(pinola_json):\n",
    "    raise FileNotFoundError(f\"File {pinola_json} not found.\"\n",
    "                            \"Please run example e11 to generate network topology.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read nodes...\n",
      "******\n",
      " input_ids were {'buildings': None, 'nodes': 'f607cb63-8aed-446c-9970-9cd8380434f8', 'pipes': None, 'supplies': None}\n",
      "...finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "graph = ug.UESGraph()\n",
    "graph.from_json(path = pinola_json, network_type=\"heating\")\n",
    "graph.graph[\"name\"] = \"pinola\"\n",
    "graph.graph[\"supply_type\"] = \"supply\"\n",
    "\n",
    "start_date=datetime(2024, 1, 1) \n",
    "end_date=datetime(2024, 1, 7)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logfile findable here: C:\\Users\\rka-lko\\AppData\\Local\\Temp\\uesgraphs.analysis.data_handling.data_handling.assign_data_to_uesgraphs_20250605_181236.log\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_node_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m gr = \u001b[43manalysis\u001b[49m\u001b[43m.\u001b[49m\u001b[43massign_simulation_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpinola_sim_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43maixlib_version\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m2.0.0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mauto_retry\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\rka-lko\\git\\uesgraphs\\uesgraphs\\analysis\\data_handling\\data_handling.py:554\u001b[39m, in \u001b[36massign_simulation_data\u001b[39m\u001b[34m(graph, sim_data, start_date, end_date, aixlib_version, time_interval, auto_retry, validate_network, log_dir)\u001b[39m\n\u001b[32m    551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m graph_with_nodes\n\u001b[32m    553\u001b[39m \u001b[38;5;66;03m# First attempt with specified version\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m result = \u001b[43m_attempt_assignment\u001b[49m\u001b[43m(\u001b[49m\u001b[43maixlib_version\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    555\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m    556\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mUESGraph data assignment completed successfully\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\rka-lko\\git\\uesgraphs\\uesgraphs\\analysis\\data_handling\\data_handling.py:518\u001b[39m, in \u001b[36massign_simulation_data.<locals>._attempt_assignment\u001b[39m\u001b[34m(version)\u001b[39m\n\u001b[32m    516\u001b[39m \u001b[38;5;66;03m# Assign node values (pressure and temperature)\u001b[39;00m\n\u001b[32m    517\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mAssigning node values (pressure and temperature)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m518\u001b[39m graph_with_nodes = \u001b[43mget_node_values\u001b[49m(graph, df.iloc[\u001b[32m0\u001b[39m], \n\u001b[32m    519\u001b[39m                                  pipe_type=supply_type_prefix[supply_type],\n\u001b[32m    520\u001b[39m                                  logger=logger)\n\u001b[32m    522\u001b[39m \u001b[38;5;66;03m# Assign time series data to nodes\u001b[39;00m\n\u001b[32m    523\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mAssigning time series data to nodes\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'get_node_values' is not defined"
     ]
    }
   ],
   "source": [
    "gr = analysis.assign_simulation_data(graph, pinola_sim_data, start_date, end_date,aixlib_version=\"2.0.0\",auto_retry=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logfile findable here: C:\\Users\\rka-lko\\AppData\\Local\\Temp\\3\\SystemModelHeating_20250821_152127.log\n",
      "Warning: Could not set attribute time: property 'time' of 'SystemModelHeating' object has no setter\n",
      "Model loaded from E:\\rka_lko\\git\\transurban_seestadt\\dhc_model\\workspace\\model.json\n"
     ]
    }
   ],
   "source": [
    "from uesgraphs.systemmodels import utilities as ut\n",
    "sysm_graph = ut.load_system_model_from_json(sysm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uesgraphs.analysis.data_handling import graph_transformation\n",
    "port_mapping = graph_transformation.map_system_model_to_uesgraph(sysm_graph,graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "uesgraphs.analysis.data_handling.data_handling.get_MASKS - INFO - Using AixLib version 2.1.0 masks\n",
      "uesgraphs.analysis.data_handling.data_handling.process_parquet_file - INFO - Found existing gzip file: E:\\rka_lko\\work\\2025_04_analysis\\10042025SeestadtNewSim\\Sim20250409_190504_detailed\\Sim20250409_190504_1\\Results\\Sim20250409_190504_1_inputs.gzip\n",
      "uesgraphs.analysis.data_handling.data_handling.process_parquet_file - INFO - Validating 72 required columns in: E:\\rka_lko\\work\\2025_04_analysis\\10042025SeestadtNewSim\\Sim20250409_190504_detailed\\Sim20250409_190504_1\\Results\\Sim20250409_190504_1_inputs.gzip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter-Liste mit 72 Variablen:\n",
      "  - networkModel.pipe10021010.port_a.m_flow\n",
      "  - networkModel.pipe10021010.dp\n",
      "  - networkModel.pipe10021010.port_a.p\n",
      "  - networkModel.pipe10021010.port_b.p\n",
      "  - networkModel.pipe10021010.sta_a.T\n",
      "  - networkModel.pipe10021010.sta_b.T\n",
      "  - networkModel.pipe10021014.port_a.m_flow\n",
      "  - networkModel.pipe10021014.dp\n",
      "  - networkModel.pipe10021014.port_a.p\n",
      "  - networkModel.pipe10021014.port_b.p\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "uesgraphs.analysis.data_handling.data_handling.process_parquet_file - INFO - ✅ All required columns found in data file\n",
      "uesgraphs.analysis.data_handling.data_handling.process_parquet_file - INFO - Starting parquet file processing: E:\\rka_lko\\work\\2025_04_analysis\\10042025SeestadtNewSim\\Sim20250409_190504_detailed\\Sim20250409_190504_1\\Results\\Sim20250409_190504_1_inputs.gzip\n",
      "uesgraphs.analysis.data_handling.data_handling.process_parquet_file - INFO - Successfully loaded 35041 rows, 72 columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame Shape: (35041, 72)\n",
      "Spalten: ['networkModel.pipe10021010.port_a.m_flow', 'networkModel.pipe10021010.dp', 'networkModel.pipe10021010.port_a.p', 'networkModel.pipe10021010.port_b.p', 'networkModel.pipe10021010.sta_a.T', 'networkModel.pipe10021010.sta_b.T', 'networkModel.pipe10021014.port_a.m_flow', 'networkModel.pipe10021014.dp', 'networkModel.pipe10021014.port_a.p', 'networkModel.pipe10021014.port_b.p', 'networkModel.pipe10021014.sta_a.T', 'networkModel.pipe10021014.sta_b.T', 'networkModel.pipe10021025.port_a.m_flow', 'networkModel.pipe10021025.dp', 'networkModel.pipe10021025.port_a.p', 'networkModel.pipe10021025.port_b.p', 'networkModel.pipe10021025.sta_a.T', 'networkModel.pipe10021025.sta_b.T', 'networkModel.pipe10041006.port_a.m_flow', 'networkModel.pipe10041006.dp', 'networkModel.pipe10041006.port_a.p', 'networkModel.pipe10041006.port_b.p', 'networkModel.pipe10041006.sta_a.T', 'networkModel.pipe10041006.sta_b.T', 'networkModel.pipe10041007.port_a.m_flow', 'networkModel.pipe10041007.dp', 'networkModel.pipe10041007.port_a.p', 'networkModel.pipe10041007.port_b.p', 'networkModel.pipe10041007.sta_a.T', 'networkModel.pipe10041007.sta_b.T', 'networkModel.pipe10041027.port_a.m_flow', 'networkModel.pipe10041027.dp', 'networkModel.pipe10041027.port_a.p', 'networkModel.pipe10041027.port_b.p', 'networkModel.pipe10041027.sta_a.T', 'networkModel.pipe10041027.sta_b.T', 'networkModel.pipe10061022.port_a.m_flow', 'networkModel.pipe10061022.dp', 'networkModel.pipe10061022.port_a.p', 'networkModel.pipe10061022.port_b.p', 'networkModel.pipe10061022.sta_a.T', 'networkModel.pipe10061022.sta_b.T', 'networkModel.pipe10071018.port_a.m_flow', 'networkModel.pipe10071018.dp', 'networkModel.pipe10071018.port_a.p', 'networkModel.pipe10071018.port_b.p', 'networkModel.pipe10071018.sta_a.T', 'networkModel.pipe10071018.sta_b.T', 'networkModel.pipe10101029.port_a.m_flow', 'networkModel.pipe10101029.dp', 'networkModel.pipe10101029.port_a.p', 'networkModel.pipe10101029.port_b.p', 'networkModel.pipe10101029.sta_a.T', 'networkModel.pipe10101029.sta_b.T', 'networkModel.pipe10141022.port_a.m_flow', 'networkModel.pipe10141022.dp', 'networkModel.pipe10141022.port_a.p', 'networkModel.pipe10141022.port_b.p', 'networkModel.pipe10141022.sta_a.T', 'networkModel.pipe10141022.sta_b.T', 'networkModel.pipe10141026.port_a.m_flow', 'networkModel.pipe10141026.dp', 'networkModel.pipe10141026.port_a.p', 'networkModel.pipe10141026.port_b.p', 'networkModel.pipe10141026.sta_a.T', 'networkModel.pipe10141026.sta_b.T', 'networkModel.pipe10181028.port_a.m_flow', 'networkModel.pipe10181028.dp', 'networkModel.pipe10181028.port_a.p', 'networkModel.pipe10181028.port_b.p', 'networkModel.pipe10181028.sta_a.T', 'networkModel.pipe10181028.sta_b.T']\n"
     ]
    }
   ],
   "source": [
    "# 1. Supply Type und Masks laden\n",
    "supply_type = graph.graph[\"supply_type\"]  # \"supply\" oder \"return\"\n",
    "supply_type_prefix = {\"supply\": \"\", \"return\": \"R\"}\n",
    "\n",
    "from uesgraphs.analysis.data_handling.data_handling import get_MASKS\n",
    "masks = get_MASKS(\"2.1.0\")  # oder deine gewünschte Version\n",
    "\n",
    "# 2. Filter-Liste bauen (wie im existierenden Code)\n",
    "filter_list = []\n",
    "for edge in graph.edges:\n",
    "    pipe_code = graph.edges[edge][\"name\"]\n",
    "    for mask_type, mask_pattern in masks.items():\n",
    "        var_name = mask_pattern.format(\n",
    "            pipe_code=pipe_code, \n",
    "            type=supply_type_prefix[supply_type]\n",
    "        )\n",
    "        filter_list.append(var_name)\n",
    "\n",
    "print(f\"Filter-Liste mit {len(filter_list)} Variablen:\")\n",
    "for var in filter_list[:10]:  # Erste 10 zeigen\n",
    "    print(f\"  - {var}\")\n",
    "\n",
    "# 3. Daten laden\n",
    "from uesgraphs.analysis.data_handling.data_handling import process_simulation_result\n",
    "df = process_simulation_result(file_path=pinola_sim_data, filter_list=filter_list)\n",
    "\n",
    "print(f\"\\nDataFrame Shape: {df.shape}\")\n",
    "print(f\"Spalten: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'m_flow': 'networkModel.pipe{pipe_code}{type}.port_a.m_flow',\n",
       " 'dp': 'networkModel.pipe{pipe_code}{type}.dp',\n",
       " 'p_a': 'networkModel.pipe{pipe_code}{type}.port_a.p',\n",
       " 'p_b': 'networkModel.pipe{pipe_code}{type}.port_b.p',\n",
       " 'T_a': 'networkModel.pipe{pipe_code}{type}.sta_a.T',\n",
       " 'T_b': 'networkModel.pipe{pipe_code}{type}.sta_b.T'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pipe10021014.port_a'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1001\n",
    "node_ports = port_mapping[i]  # Liste aller Ports für diesen Node\n",
    "collected_values = {\"T\": [], \"p\": []}\n",
    "\n",
    "# Mapping für flexible Attributnamen im Graph\n",
    "attribute_names = {\"T\": \"temperature\", \"p\": \"press_flow\"}  # Konfigurierbar!\n",
    "\n",
    "for port in node_ports:  # Iteriere über ALLE Ports des Nodes\n",
    "    port_splitted = port.split(\".\")\n",
    "    if port_splitted[1].endswith(\"a\"):\n",
    "        #port is an a port\n",
    "        temp = f\"networkModel.{port_splitted[0]}.sta_a.T\"\n",
    "        press = f\"networkModel.{port_splitted[0]}.port_a.p\"\n",
    "        t_value = df[temp].iloc[0]\n",
    "        p_value = df[press].iloc[0]\n",
    "        collected_values[\"T\"].append(t_value)\n",
    "        collected_values[\"p\"].append(p_value)\n",
    "\n",
    "# Validiere und weise zu\n",
    "for size in [\"T\", \"p\"]:\n",
    "    unique_vals = set(collected_values[size])\n",
    "    if len(unique_vals) != 1:\n",
    "        raise ValueError(f\"Node {i}: Inkonsistente {size}-Werte gefunden: {collected_values[size]}\")\n",
    "    graph.nodes[i][attribute_names[size]] = collected_values[size][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Port Mapping für Knoten {i}: {port}\")\n",
    "pipe_mask = df.columns.str.contains('pipe10021014.')\n",
    "df_pipe = df.loc[:, pipe_mask]\n",
    "print(f\"Gefundene Spalten: {df.columns[pipe_mask].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge (1001, 1005) has data: {'diameter': 0.0697, 'length': 62.67448664094058, 'pipeID': '10021010', 'name': '10021010', 'node_0': 1002, 'node_1': 1010}\n",
      "Edge (1001, 1006) has data: {'diameter': 0.2101, 'length': 40.10060652984215, 'pipeID': '10021014', 'name': '10021014', 'node_0': 1002, 'node_1': 1014}\n",
      "Edge (1001, 1009) has data: {'diameter': 0.2101, 'length': 23.793988913832845, 'pipeID': '10021025', 'name': '10021025', 'node_0': 1002, 'node_1': 'supply1'}\n",
      "Edge (1002, 1003) has data: {'diameter': 0.1325, 'length': 23.15227945754485, 'pipeID': '10041006', 'name': '10041006', 'node_0': 1004, 'node_1': 1006}\n",
      "Edge (1002, 1004) has data: {'diameter': 0.1325, 'length': 67.21343661070965, 'pipeID': '10041007', 'name': '10041007', 'node_0': 1004, 'node_1': 1007}\n",
      "Edge (1002, 1011) has data: {'diameter': 0.0539, 'length': 25.20026053450003, 'pipeID': '10041027', 'name': '10041027', 'node_0': 1004, 'node_1': 'w11_2'}\n",
      "Edge (1003, 1008) has data: {'diameter': 0.2101, 'length': 43.10762795752977, 'pipeID': '10061022', 'name': '10061022', 'node_0': 1006, 'node_1': 1022}\n",
      "Edge (1004, 1007) has data: {'diameter': 0.1071, 'length': 41.06543024277208, 'pipeID': '10071018', 'name': '10071018', 'node_0': 1007, 'node_1': 1018}\n",
      "Edge (1005, 1013) has data: {'diameter': 0.0697, 'length': 17.635612191884555, 'pipeID': '10101029', 'name': '10101029', 'node_0': 1010, 'node_1': 'w11_4'}\n",
      "Edge (1006, 1008) has data: {'diameter': 0.2101, 'length': 42.097964605664814, 'pipeID': '10141022', 'name': '10141022', 'node_0': 1014, 'node_1': 1022}\n",
      "Edge (1006, 1010) has data: {'diameter': 0.0539, 'length': 18.20446528640188, 'pipeID': '10141026', 'name': '10141026', 'node_0': 1014, 'node_1': 'w11_3'}\n",
      "Edge (1007, 1012) has data: {'diameter': 0.0697, 'length': 22.026936306526547, 'pipeID': '10181028', 'name': '10181028', 'node_0': 1018, 'node_1': 'w11_1'}\n"
     ]
    }
   ],
   "source": [
    "edges = list(graph.edges)\n",
    "for edge in edges:\n",
    "    print(f\"Edge {edge} has data: {graph.edges[edge]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    graph = analyze.assign_data_to_uesgraphs(graph,sim_data = pinola_sim_data,\n",
    "                                             start_date=start_date,\n",
    "                                             end_date=end_date,\n",
    "                                             aixlib_version=\"2.1.0\") #aixlib version is needed to assign data properly\n",
    "    \n",
    "    ### Plotting\n",
    "    #Visuals cant handle series data, so we just take the mean values, but single time points are possible\n",
    "    vis = ug.Visuals(graph)\n",
    "    for edge in graph.edges:\n",
    "        graph.edges[edge][\"m_flow_mean\"] = graph.edges[edge][\"m_flow\"].mean()\n",
    "    vis.show_network(show_plot=False,\n",
    "                           scaling_factor=1,\n",
    "                           scaling_factor_diameter=50,\n",
    "                           label_size=15,\n",
    "                           ylabel=\"Mean mass flow [kg/s]\",\n",
    "                           generic_extensive_size=\"m_flow_mean\",\n",
    "                           save_as=os.path.join(workspace, \"m_flow.png\"),\n",
    "                           timestamp=f\"{graph.graph[\"name\"]}: Mean mass flow\"\n",
    "                           )\n",
    "    \n",
    "    for node in graph.nodes:\n",
    "        graph.nodes[node][\"press_flow_mean\"] = graph.nodes[node][\"press_flow\"].mean()\n",
    "    vis.show_network(show_plot=False,\n",
    "                           scaling_factor=1,\n",
    "                           scaling_factor_diameter=50,\n",
    "                           ylabel=\"Mean pressure [Pa]\",\n",
    "                           label_size=15,\n",
    "                           generic_intensive_size=\"press_flow_mean\",\n",
    "                           save_as=os.path.join(workspace, \"press_flow.png\"),\n",
    "                           timestamp=f\"{graph.graph[\"name\"]}: Mean pressure flow\"\n",
    "                           )\n",
    "    \n",
    "    df = analyze.pump_power_analysis(graph, True, r\"D:\\rka-lko\\work\\2025_04_analysis\\3\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "source": "# Example: Before/After demonstration of node value assignment\nprint(\"=== BEFORE NODE VALUE ASSIGNMENT ===\")\nsample_nodes = list(graph.nodes)[:5]  # Take first 5 nodes as examples\n\nprint(\"Sample nodes before assignment:\")\nfor node_id in sample_nodes:\n    node_data = graph.nodes[node_id]\n    temp = node_data.get('temperature', 'NOT SET')\n    pressure = node_data.get('pressure', 'NOT SET')\n    print(f\"Node {node_id}: Temperature = {temp}, Pressure = {pressure}\")\n\nprint(f\"\\nTotal nodes in graph: {len(graph.nodes)}\")\nnodes_with_temp = sum(1 for n in graph.nodes if 'temperature' in graph.nodes[n])\nnodes_with_pressure = sum(1 for n in graph.nodes if 'pressure' in graph.nodes[n])\nprint(f\"Nodes with temperature: {nodes_with_temp}\")\nprint(f\"Nodes with pressure: {nodes_with_pressure}\")\n\n# Run the assignment\nprint(\"\\n\" + \"=\"*50)\nprint(\"RUNNING NODE VALUE ASSIGNMENT...\")\nprint(\"=\"*50)\n\nconfig = {\n    \"temperature\": [\"sta_{port}.T\"],\n    \"pressure\": [\"port_{port}.p\"], \n}\n\nprocessed, inconsistencies, conflicts = assign_node_values_flexible(graph, df, port_mapping, config)\n\nprint(\"\\n=== AFTER NODE VALUE ASSIGNMENT ===\")\nprint(\"Sample nodes after assignment:\")\nfor node_id in sample_nodes:\n    node_data = graph.nodes[node_id]\n    temp = node_data.get('temperature', 'STILL NOT SET')\n    pressure = node_data.get('pressure', 'STILL NOT SET')\n    if isinstance(temp, float):\n        temp = f\"{temp:.3f}\"\n    if isinstance(pressure, float):\n        pressure = f\"{pressure:.3f}\"\n    print(f\"Node {node_id}: Temperature = {temp}, Pressure = {pressure}\")\n\n# Summary statistics\nnodes_with_temp_after = sum(1 for n in graph.nodes if 'temperature' in graph.nodes[n])\nnodes_with_pressure_after = sum(1 for n in graph.nodes if 'pressure' in graph.nodes[n])\nprint(f\"\\nSUMMARY:\")\nprint(f\"Nodes with temperature: {nodes_with_temp} → {nodes_with_temp_after}\")\nprint(f\"Nodes with pressure: {nodes_with_pressure} → {nodes_with_pressure_after}\")\nprint(f\"Success rate: {nodes_with_temp_after}/{len(graph.nodes)} = {nodes_with_temp_after/len(graph.nodes)*100:.1f}%\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def assign_node_values_flexible(graph, df, port_mapping, attribute_config, time_index=0):\n    \"\"\"\n    Flexible node value assignment with pattern validation\n    \n    Now checks if multiple patterns for the same attribute give consistent results\n    \"\"\"\n    \n    processed_count = 0\n    inconsistency_count = 0\n    pattern_conflicts = 0\n    \n    for node_id, node_ports in port_mapping.items():\n        if not node_ports:\n            continue\n            \n        for attr_name, patterns in attribute_config.items():\n            all_values_by_pattern = {}  # Track values from each pattern\n            \n            for port in node_ports:\n                port_parts = port.split(\".\")\n                pipe_name = port_parts[0]\n                port_suffix = port_parts[1].split(\"_\")[-1]  # Extract 'a' or 'b'\n                \n                # Test ALL patterns and collect their values\n                for pattern in patterns:\n                    col_name = f\"networkModel.{pipe_name}.{pattern.format(port=port_suffix)}\"\n                    if col_name in df.columns:\n                        value = df[col_name].iloc[time_index]\n                        \n                        if pattern not in all_values_by_pattern:\n                            all_values_by_pattern[pattern] = []\n                        all_values_by_pattern[pattern].append(value)\n            \n            # Now check if different patterns give consistent results\n            if len(all_values_by_pattern) > 1:\n                # Multiple patterns found data - check consistency\n                pattern_means = {}\n                for pattern, values in all_values_by_pattern.items():\n                    pattern_means[pattern] = sum(values) / len(values)\n                \n                # Check if all patterns agree (within tolerance)\n                mean_values = list(pattern_means.values())\n                if len(set(round(v, 6) for v in mean_values)) > 1:\n                    print(f\"Pattern conflict for {attr_name} at node {node_id}:\")\n                    for pattern, mean_val in pattern_means.items():\n                        print(f\"  {pattern}: {mean_val:.6f}\")\n                    pattern_conflicts += 1\n            \n            # Use values from the first successful pattern\n            if all_values_by_pattern:\n                first_pattern = list(all_values_by_pattern.keys())[0]\n                collected_values = all_values_by_pattern[first_pattern]\n                \n                # Check consistency within the chosen pattern\n                unique_vals = set(round(v, 6) for v in collected_values)\n                \n                if len(unique_vals) == 1:\n                    graph.nodes[node_id][attr_name] = collected_values[0]\n                else:\n                    mean_val = sum(collected_values) / len(collected_values)\n                    graph.nodes[node_id][attr_name] = mean_val\n                    print(f\"Warning: Node {node_id} inconsistent {attr_name} within pattern: using mean {mean_val:.3f}\")\n                    inconsistency_count += 1\n        \n        processed_count += 1\n    \n    print(f\"Processed {processed_count} nodes\")\n    print(f\"Within-pattern inconsistencies: {inconsistency_count}\")\n    print(f\"Cross-pattern conflicts: {pattern_conflicts}\")\n    return processed_count, inconsistency_count, pattern_conflicts\n\n# Usage example with configurable patterns\nconfig = {\n    \"temperature\": [\"sta_{port}.T\"],\n    \"pressure\": [\"port_{port}.p\"], \n    # Future example: test multiple patterns for enthalpy\n    # \"enthalpy\": [\"port_{port}.h\", \"sta_{port}.h\"]  \n}\n\nprocessed, inconsistencies, conflicts = assign_node_values_flexible(graph, df, port_mapping, config)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uesgraphs1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}