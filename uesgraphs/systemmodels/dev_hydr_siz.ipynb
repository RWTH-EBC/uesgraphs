{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uesgraphs.uesgraph import UESGraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "json = r\"D:\\rka-lko\\git\\uesgraphs\\workspace\\e11\\inputs\\test_modelgen\\Ibpsa\\nodes.json\"\n",
    "json = r\"D:\\rka-lko\\git\\uesgraphs\\workspace\\e11\\inputs\\test_modelgen\\Pinola\\nodes.json\"\n",
    "json = \"/home/leon/git/uesgraphs_github/uesgraphs/workspace/e10/tests/test_modelgen/Ibpsa/\"\n",
    "graph = UESGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read nodes...\n",
      "******\n",
      " input_ids were {'buildings': None, 'nodes': 'f8a0e23d-465f-41f2-918e-4afbd5994b9e', 'pipes': None, 'supplies': None}\n",
      "...finished\n"
     ]
    }
   ],
   "source": [
    "graph.from_json(path=json,network_type=\"heating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import uesgraphs.systemmodels.utilities as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph2 = ut.estimate_m_flow_nominal(graph,30,\"heating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "from typing import Any, Dict, List, Optional, Set, Tuple\n",
    "\n",
    "import networkx as nx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'point_3',\n",
       " 'node_type': 'building',\n",
       " 'position': <POINT (0 0)>,\n",
       " 'is_supply_heating': False,\n",
       " 'is_supply_cooling': False,\n",
       " 'is_supply_electricity': False,\n",
       " 'is_supply_gas': False,\n",
       " 'is_supply_other': False,\n",
       " 'input_heat': [3640.07987448,\n",
       "  3514.56012552,\n",
       "  3891.11987448,\n",
       "  3640.07987448,\n",
       "  4393.2,\n",
       "  4393.2,\n",
       "  3640.07987448,\n",
       "  4142.16,\n",
       "  3891.11987448,\n",
       "  4142.16,\n",
       "  3891.11987448,\n",
       "  3891.11987448,\n",
       "  4142.16,\n",
       "  4016.6402510400003,\n",
       "  3891.11987448,\n",
       "  3891.11987448,\n",
       "  3640.07987448,\n",
       "  4267.68025104,\n",
       "  4267.68025104,\n",
       "  3891.11987448,\n",
       "  4142.16,\n",
       "  10418.159623440002,\n",
       "  8284.32,\n",
       "  8033.28037656,\n",
       "  8033.28037656,\n",
       "  13305.119999999999,\n",
       "  1882.7999999999997,\n",
       "  7782.23987448,\n",
       "  7405.68,\n",
       "  7405.68,\n",
       "  7405.68,\n",
       "  7029.12025104,\n",
       "  7405.68,\n",
       "  6150.479874480001,\n",
       "  7405.68,\n",
       "  5773.919999999999,\n",
       "  5773.919999999999,\n",
       "  6527.0401255199995,\n",
       "  5522.879999999999,\n",
       "  5397.36012552,\n",
       "  5271.839874480001,\n",
       "  4518.71974896,\n",
       "  4518.71974896,\n",
       "  4393.2,\n",
       "  4769.759874480001,\n",
       "  5146.32012552,\n",
       "  4644.24,\n",
       "  4518.71974896,\n",
       "  4518.71974896,\n",
       "  4644.24,\n",
       "  4016.6402510400003,\n",
       "  4393.2,\n",
       "  4016.6402510400003,\n",
       "  4769.759874480001,\n",
       "  3891.11987448,\n",
       "  3891.11987448,\n",
       "  4016.6402510400003,\n",
       "  7656.72012552,\n",
       "  3640.07987448,\n",
       "  4142.16,\n",
       "  3640.07987448,\n",
       "  3640.07987448,\n",
       "  4267.68025104,\n",
       "  3640.07987448,\n",
       "  3765.59987448,\n",
       "  3514.56012552,\n",
       "  3640.07987448,\n",
       "  3640.07987448,\n",
       "  3765.59987448,\n",
       "  3765.59987448,\n",
       "  3891.11987448,\n",
       "  3891.11987448,\n",
       "  3891.11987448,\n",
       "  3891.11987448,\n",
       "  3765.59987448,\n",
       "  3891.11987448,\n",
       "  4016.6402510400003,\n",
       "  4393.2,\n",
       "  3891.11987448,\n",
       "  3891.11987448,\n",
       "  4142.16,\n",
       "  125.52,\n",
       "  1631.7599999999998,\n",
       "  2384.87987448,\n",
       "  2008.3201255200001,\n",
       "  2008.3201255200001,\n",
       "  2510.4,\n",
       "  2008.3201255200001,\n",
       "  2635.92,\n",
       "  2635.92,\n",
       "  2635.92,\n",
       "  2008.3201255200001,\n",
       "  2008.3201255200001,\n",
       "  2635.92,\n",
       "  2510.4,\n",
       "  2635.92,\n",
       "  2510.4,\n",
       "  2510.4,\n",
       "  2510.4,\n",
       "  2510.4,\n",
       "  2761.4399999999996,\n",
       "  2384.87987448,\n",
       "  2635.92,\n",
       "  2510.4,\n",
       "  2510.4,\n",
       "  2761.4399999999996,\n",
       "  2510.4,\n",
       "  2886.9599999999996,\n",
       "  2635.92,\n",
       "  2886.9599999999996,\n",
       "  2886.9599999999996,\n",
       "  2761.4399999999996,\n",
       "  3138.0,\n",
       "  2886.9599999999996,\n",
       "  3263.52012552,\n",
       "  3138.0,\n",
       "  3138.0,\n",
       "  3640.07987448,\n",
       "  6652.55987448,\n",
       "  6903.599999999999,\n",
       "  6527.0401255199995,\n",
       "  12677.52,\n",
       "  12677.52,\n",
       "  6652.55987448,\n",
       "  7405.68,\n",
       "  6652.55987448,\n",
       "  7154.639999999999,\n",
       "  6903.599999999999,\n",
       "  6903.599999999999,\n",
       "  7405.68,\n",
       "  7907.76012552,\n",
       "  7029.12025104,\n",
       "  6276.00012552,\n",
       "  5773.919999999999,\n",
       "  5773.919999999999,\n",
       "  4895.28012552,\n",
       "  4518.71974896,\n",
       "  4142.16,\n",
       "  4769.759874480001,\n",
       "  5271.839874480001,\n",
       "  5271.839874480001,\n",
       "  4518.71974896,\n",
       "  4895.28012552,\n",
       "  4518.71974896,\n",
       "  4769.759874480001,\n",
       "  4518.71974896,\n",
       "  4518.71974896,\n",
       "  4518.71974896,\n",
       "  4142.16,\n",
       "  3891.11987448,\n",
       "  4142.16,\n",
       "  3891.11987448,\n",
       "  4142.16,\n",
       "  4142.16,\n",
       "  3389.04012552,\n",
       "  3765.59987448,\n",
       "  3640.07987448,\n",
       "  3765.59987448,\n",
       "  3765.59987448,\n",
       "  3765.59987448,\n",
       "  3765.59987448,\n",
       "  6150.479874480001,\n",
       "  4769.759874480001,\n",
       "  4142.16,\n",
       "  4267.68025104,\n",
       "  4267.68025104,\n",
       "  4393.2,\n",
       "  5146.32012552,\n",
       "  4895.28012552,\n",
       "  3389.04012552,\n",
       "  4267.68025104,\n",
       "  4267.68025104,\n",
       "  4267.68025104,\n",
       "  4895.28012552,\n",
       "  4016.6402510400003,\n",
       "  4895.28012552,\n",
       "  4267.68025104,\n",
       "  4267.68025104,\n",
       "  2510.4,\n",
       "  2133.84012552,\n",
       "  2133.84012552,\n",
       "  2259.35987448,\n",
       "  2384.87987448,\n",
       "  2384.87987448,\n",
       "  2259.35987448,\n",
       "  2259.35987448,\n",
       "  2761.4399999999996,\n",
       "  2635.92,\n",
       "  2761.4399999999996,\n",
       "  2761.4399999999996,\n",
       "  2635.92,\n",
       "  2635.92,\n",
       "  2635.92,\n",
       "  2886.9599999999996,\n",
       "  2635.92,\n",
       "  2635.92,\n",
       "  2886.9599999999996,\n",
       "  2886.9599999999996,\n",
       "  2635.92,\n",
       "  2635.92,\n",
       "  2635.92,\n",
       "  2635.92,\n",
       "  2635.92,\n",
       "  2761.4399999999996,\n",
       "  2635.92,\n",
       "  2761.4399999999996,\n",
       "  2510.4,\n",
       "  2886.9599999999996,\n",
       "  2886.9599999999996,\n",
       "  2635.92,\n",
       "  2886.9599999999996,\n",
       "  2635.92,\n",
       "  2886.9599999999996,\n",
       "  4393.2,\n",
       "  4393.2,\n",
       "  4644.24,\n",
       "  4016.6402510400003,\n",
       "  8786.4,\n",
       "  5397.36012552,\n",
       "  4895.28012552,\n",
       "  4895.28012552,\n",
       "  4895.28012552,\n",
       "  4644.24,\n",
       "  5146.32012552,\n",
       "  5146.32012552,\n",
       "  4895.28012552,\n",
       "  4895.28012552,\n",
       "  4769.759874480001,\n",
       "  4393.2,\n",
       "  7656.72012552,\n",
       "  5648.40025104,\n",
       "  5146.32012552,\n",
       "  5146.32012552,\n",
       "  5271.839874480001,\n",
       "  3891.11987448,\n",
       "  3765.59987448,\n",
       "  3891.11987448,\n",
       "  3891.11987448,\n",
       "  3891.11987448,\n",
       "  3514.56012552,\n",
       "  3514.56012552,\n",
       "  3891.11987448,\n",
       "  3514.56012552,\n",
       "  3640.07987448,\n",
       "  3640.07987448,\n",
       "  3514.56012552,\n",
       "  3514.56012552,\n",
       "  4016.6402510400003,\n",
       "  3514.56012552,\n",
       "  4142.16,\n",
       "  3514.56012552,\n",
       "  3514.56012552,\n",
       "  4393.2,\n",
       "  4016.6402510400003,\n",
       "  4518.71974896,\n",
       "  3891.11987448,\n",
       "  4393.2,\n",
       "  4393.2,\n",
       "  4518.71974896,\n",
       "  4267.68025104,\n",
       "  7907.76012552,\n",
       "  5522.879999999999,\n",
       "  5271.839874480001,\n",
       "  5271.839874480001,\n",
       "  5146.32012552,\n",
       "  2259.35987448,\n",
       "  4016.6402510400003,\n",
       "  4895.28012552,\n",
       "  4895.28012552,\n",
       "  4895.28012552,\n",
       "  5522.879999999999,\n",
       "  5146.32012552,\n",
       "  5648.40025104,\n",
       "  1757.28,\n",
       "  2384.87987448,\n",
       "  2384.87987448,\n",
       "  3263.52012552,\n",
       "  2886.9599999999996,\n",
       "  2761.4399999999996,\n",
       "  3012.48,\n",
       "  3138.0,\n",
       "  3138.0,\n",
       "  3389.04012552,\n",
       "  3389.04012552,\n",
       "  3514.56012552,\n",
       "  3640.07987448,\n",
       "  3514.56012552,\n",
       "  3514.56012552,\n",
       "  4016.6402510400003,\n",
       "  4142.16,\n",
       "  4016.6402510400003,\n",
       "  4142.16,\n",
       "  4142.16,\n",
       "  4142.16,\n",
       "  4142.16,\n",
       "  4518.71974896,\n",
       "  4393.2,\n",
       "  4267.68025104,\n",
       "  4267.68025104,\n",
       "  4895.28012552,\n",
       "  4895.28012552,\n",
       "  4644.24,\n",
       "  4895.28012552,\n",
       "  4393.2,\n",
       "  4518.71974896,\n",
       "  4267.68025104,\n",
       "  4267.68025104,\n",
       "  4769.759874480001,\n",
       "  4895.28012552,\n",
       "  7656.72012552,\n",
       "  7782.23987448,\n",
       "  7782.23987448,\n",
       "  7782.23987448,\n",
       "  7405.68,\n",
       "  13932.720000000001,\n",
       "  11673.36025104,\n",
       "  125.52,\n",
       "  7656.72012552,\n",
       "  7656.72012552,\n",
       "  7656.72012552,\n",
       "  7154.639999999999,\n",
       "  7154.639999999999,\n",
       "  7154.639999999999,\n",
       "  6903.599999999999,\n",
       "  5899.4397489600005,\n",
       "  6150.479874480001,\n",
       "  5146.32012552,\n",
       "  5146.32012552,\n",
       "  4142.16,\n",
       "  4142.16,\n",
       "  4518.71974896,\n",
       "  5020.799874480001,\n",
       "  5271.839874480001,\n",
       "  5271.839874480001,\n",
       "  4895.28012552,\n",
       "  5020.799874480001,\n",
       "  4895.28012552,\n",
       "  5522.879999999999,\n",
       "  5146.32012552,\n",
       "  5146.32012552,\n",
       "  4895.28012552,\n",
       "  4267.68025104,\n",
       "  4267.68025104,\n",
       "  4267.68025104,\n",
       "  4769.759874480001,\n",
       "  4769.759874480001,\n",
       "  4142.16,\n",
       "  4016.6402510400003,\n",
       "  4769.759874480001,\n",
       "  4142.16,\n",
       "  5020.799874480001,\n",
       "  4518.71974896,\n",
       "  4518.71974896,\n",
       "  4518.71974896,\n",
       "  4769.759874480001,\n",
       "  4644.24,\n",
       "  5397.36012552,\n",
       "  5522.879999999999,\n",
       "  5522.879999999999,\n",
       "  6276.00012552,\n",
       "  5522.879999999999,\n",
       "  5397.36012552,\n",
       "  6401.51987448,\n",
       "  5648.40025104,\n",
       "  5648.40025104,\n",
       "  5773.919999999999,\n",
       "  5899.4397489600005,\n",
       "  6024.96,\n",
       "  6778.0801255199995,\n",
       "  376.56,\n",
       "  376.56,\n",
       "  3138.0,\n",
       "  2886.9599999999996,\n",
       "  3138.0,\n",
       "  3012.48,\n",
       "  3012.48,\n",
       "  3012.48,\n",
       "  3389.04012552,\n",
       "  3138.0,\n",
       "  3138.0,\n",
       "  3012.48,\n",
       "  3138.0,\n",
       "  3138.0,\n",
       "  3640.07987448,\n",
       "  3514.56012552,\n",
       "  3389.04012552,\n",
       "  3012.48,\n",
       "  3012.48,\n",
       "  3012.48,\n",
       "  3138.0,\n",
       "  3012.48,\n",
       "  3263.52012552,\n",
       "  3389.04012552,\n",
       "  3514.56012552,\n",
       "  3389.04012552,\n",
       "  3389.04012552,\n",
       "  3640.07987448,\n",
       "  3765.59987448,\n",
       "  3765.59987448,\n",
       "  3640.07987448,\n",
       "  3514.56012552,\n",
       "  3514.56012552,\n",
       "  3389.04012552,\n",
       "  3514.56012552,\n",
       "  3263.52012552,\n",
       "  8033.28037656,\n",
       "  7656.72012552,\n",
       "  7656.72012552,\n",
       "  7280.15974896,\n",
       "  6903.599999999999,\n",
       "  6652.55987448,\n",
       "  6527.0401255199995,\n",
       "  6401.51987448,\n",
       "  6401.51987448,\n",
       "  8033.28037656,\n",
       "  6276.00012552,\n",
       "  5648.40025104,\n",
       "  5146.32012552,\n",
       "  5146.32012552,\n",
       "  5899.4397489600005,\n",
       "  5146.32012552,\n",
       "  5648.40025104,\n",
       "  5146.32012552,\n",
       "  5899.4397489600005,\n",
       "  5899.4397489600005,\n",
       "  5146.32012552,\n",
       "  5146.32012552,\n",
       "  4895.28012552,\n",
       "  4895.28012552,\n",
       "  4393.2,\n",
       "  4393.2,\n",
       "  5020.799874480001,\n",
       "  4518.71974896,\n",
       "  4644.24,\n",
       "  4644.24,\n",
       "  4518.71974896,\n",
       "  4518.71974896,\n",
       "  4518.71974896,\n",
       "  4016.6402510400003,\n",
       "  4644.24,\n",
       "  4142.16,\n",
       "  4393.2,\n",
       "  4769.759874480001,\n",
       "  4769.759874480001,\n",
       "  4267.68025104,\n",
       "  4644.24,\n",
       "  4518.71974896,\n",
       "  4769.759874480001,\n",
       "  4644.24,\n",
       "  4644.24,\n",
       "  4644.24,\n",
       "  4769.759874480001,\n",
       "  5020.799874480001,\n",
       "  5146.32012552,\n",
       "  5397.36012552,\n",
       "  5397.36012552,\n",
       "  5020.799874480001,\n",
       "  5271.839874480001,\n",
       "  5146.32012552,\n",
       "  5773.919999999999,\n",
       "  4895.28012552,\n",
       "  4895.28012552,\n",
       "  5146.32012552,\n",
       "  5271.839874480001,\n",
       "  5522.879999999999,\n",
       "  1506.24,\n",
       "  1757.28,\n",
       "  1757.28,\n",
       "  2133.84012552,\n",
       "  2510.4,\n",
       "  2259.35987448,\n",
       "  2761.4399999999996,\n",
       "  2259.35987448,\n",
       "  2259.35987448,\n",
       "  2761.4399999999996,\n",
       "  2635.92,\n",
       "  2510.4,\n",
       "  2635.92,\n",
       "  2635.92,\n",
       "  2635.92,\n",
       "  2761.4399999999996,\n",
       "  2761.4399999999996,\n",
       "  2886.9599999999996,\n",
       "  2635.92,\n",
       "  2886.9599999999996,\n",
       "  2886.9599999999996,\n",
       "  2635.92,\n",
       "  3012.48,\n",
       "  2635.92,\n",
       "  2886.9599999999996,\n",
       "  2635.92,\n",
       "  2635.92,\n",
       "  3138.0,\n",
       "  2635.92,\n",
       "  2886.9599999999996,\n",
       "  2761.4399999999996,\n",
       "  3012.48,\n",
       "  3012.48,\n",
       "  2886.9599999999996,\n",
       "  3012.48,\n",
       "  2886.9599999999996,\n",
       "  7280.15974896,\n",
       "  5899.4397489600005,\n",
       "  5899.4397489600005,\n",
       "  6652.55987448,\n",
       "  13430.64,\n",
       "  7782.23987448,\n",
       "  6024.96,\n",
       "  6024.96,\n",
       "  6024.96,\n",
       "  5522.879999999999,\n",
       "  6401.51987448,\n",
       "  5899.4397489600005,\n",
       "  5899.4397489600005,\n",
       "  5899.4397489600005,\n",
       "  6024.96,\n",
       "  5397.36012552,\n",
       "  5397.36012552,\n",
       "  5899.4397489600005,\n",
       "  5522.879999999999,\n",
       "  5648.40025104,\n",
       "  4644.24,\n",
       "  5397.36012552,\n",
       "  5397.36012552,\n",
       "  5146.32012552,\n",
       "  5146.32012552,\n",
       "  5146.32012552,\n",
       "  5146.32012552,\n",
       "  5146.32012552,\n",
       "  4644.24,\n",
       "  4644.24,\n",
       "  4644.24,\n",
       "  4518.71974896,\n",
       "  4518.71974896,\n",
       "  4267.68025104,\n",
       "  4142.16,\n",
       "  4142.16,\n",
       "  4142.16,\n",
       "  4267.68025104,\n",
       "  4518.71974896,\n",
       "  4267.68025104,\n",
       "  4267.68025104,\n",
       "  3891.11987448,\n",
       "  4142.16,\n",
       "  4142.16,\n",
       "  4142.16,\n",
       "  3891.11987448,\n",
       "  4895.28012552,\n",
       "  4142.16,\n",
       "  4644.24,\n",
       "  4644.24,\n",
       "  6652.55987448,\n",
       "  4644.24,\n",
       "  4644.24,\n",
       "  4769.759874480001,\n",
       "  4769.759874480001,\n",
       "  4769.759874480001,\n",
       "  4769.759874480001,\n",
       "  5146.32012552,\n",
       "  4769.759874480001,\n",
       "  5271.839874480001,\n",
       "  4895.28012552,\n",
       "  4895.28012552,\n",
       "  5146.32012552,\n",
       "  4895.28012552,\n",
       "  125.52,\n",
       "  1506.24,\n",
       "  2635.92,\n",
       "  2635.92,\n",
       "  2384.87987448,\n",
       "  2635.92,\n",
       "  2384.87987448,\n",
       "  2635.92,\n",
       "  2384.87987448,\n",
       "  2384.87987448,\n",
       "  2761.4399999999996,\n",
       "  2635.92,\n",
       "  2886.9599999999996,\n",
       "  2761.4399999999996,\n",
       "  2886.9599999999996,\n",
       "  2886.9599999999996,\n",
       "  2761.4399999999996,\n",
       "  3012.48,\n",
       "  2761.4399999999996,\n",
       "  2886.9599999999996,\n",
       "  2886.9599999999996,\n",
       "  2886.9599999999996,\n",
       "  3012.48,\n",
       "  2635.92,\n",
       "  3012.48,\n",
       "  2635.92,\n",
       "  3012.48,\n",
       "  3012.48,\n",
       "  3012.48,\n",
       "  2886.9599999999996,\n",
       "  3012.48,\n",
       "  3012.48,\n",
       "  3012.48,\n",
       "  3012.48,\n",
       "  3012.48,\n",
       "  3138.0,\n",
       "  10418.159623440002,\n",
       "  6652.55987448,\n",
       "  5773.919999999999,\n",
       "  6150.479874480001,\n",
       "  6150.479874480001,\n",
       "  125.52,\n",
       "  6276.00012552,\n",
       "  5397.36012552,\n",
       "  6401.51987448,\n",
       "  5397.36012552,\n",
       "  5397.36012552,\n",
       "  6150.479874480001,\n",
       "  5899.4397489600005,\n",
       "  5773.919999999999,\n",
       "  5773.919999999999,\n",
       "  5773.919999999999,\n",
       "  5397.36012552,\n",
       "  6024.96,\n",
       "  6024.96,\n",
       "  5020.799874480001,\n",
       "  5020.799874480001,\n",
       "  5020.799874480001,\n",
       "  5020.799874480001,\n",
       "  4769.759874480001,\n",
       "  4769.759874480001,\n",
       "  4518.71974896,\n",
       "  4518.71974896,\n",
       "  4895.28012552,\n",
       "  4518.71974896,\n",
       "  4895.28012552,\n",
       "  4644.24,\n",
       "  4769.759874480001,\n",
       "  4142.16,\n",
       "  4142.16,\n",
       "  4393.2,\n",
       "  4267.68025104,\n",
       "  4016.6402510400003,\n",
       "  4267.68025104,\n",
       "  4267.68025104,\n",
       "  3640.07987448,\n",
       "  4393.2,\n",
       "  3891.11987448,\n",
       "  4518.71974896,\n",
       "  4267.68025104,\n",
       "  4769.759874480001,\n",
       "  4769.759874480001,\n",
       "  4016.6402510400003,\n",
       "  125.52,\n",
       "  4267.68025104,\n",
       "  4644.24,\n",
       "  4518.71974896,\n",
       "  4518.71974896,\n",
       "  4895.28012552,\n",
       "  4644.24,\n",
       "  4895.28012552,\n",
       "  4769.759874480001,\n",
       "  4895.28012552,\n",
       "  4895.28012552,\n",
       "  5020.799874480001,\n",
       "  4895.28012552,\n",
       "  251.040012552,\n",
       "  2008.3201255200001,\n",
       "  2510.4,\n",
       "  2510.4,\n",
       "  2510.4,\n",
       "  2635.92,\n",
       "  2635.92,\n",
       "  2761.4399999999996,\n",
       "  3263.52012552,\n",
       "  3263.52012552,\n",
       "  3012.48],\n",
       " 'dT_design': 30}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.nodes[1003]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logfile findable here: /tmp/hydronic_network_sizing_20250523_195016.log\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43msize_hydronic_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdT_attribute\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdT_design\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcatalog\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43misoplus\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36msize_hydronic_network\u001b[39m\u001b[34m(graph, m_flow_key, catalog, dT_attribute, network_type, demand_attribute, load_scenario, cp, logger)\u001b[39m\n\u001b[32m     38\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSizing hydronic network: estimating pipe diameters for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnetwork_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m network with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mload_scenario\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m scenario\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m catalog:\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     df = \u001b[43mload_pipe_catalog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatalog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     get_pipe_catalog_DN_m_flow(graph,pipe_catalog=df,logger=logger, mass_flow_key=m_flow_key, dn_key=\u001b[33m\"\u001b[39m\u001b[33mDN\u001b[39m\u001b[33m\"\u001b[39m, diameter_key=\u001b[33m\"\u001b[39m\u001b[33mdiameter\u001b[39m\u001b[33m\"\u001b[39m, robust=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 67\u001b[39m, in \u001b[36mload_pipe_catalog\u001b[39m\u001b[34m(catalog_name)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Check if catalog file exists\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isfile(catalog_path):\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     available_catalogs = \u001b[43m_get_available_catalogs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[32m     69\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPipe catalog \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcatalog_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m not found at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcatalog_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     70\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAvailable catalogs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavailable_catalogs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     71\u001b[39m     )\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     74\u001b[39m     \u001b[38;5;66;03m# Load CSV data, ignoring comment lines starting with '#'\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 108\u001b[39m, in \u001b[36m_get_available_catalogs\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[33;03mGet list of available pipe catalog files.\u001b[39;00m\n\u001b[32m    101\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    105\u001b[39m \u001b[33;03m    List of available catalog names (without .csv extension)\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     current_dir = os.path.dirname(\u001b[34;43m__file__\u001b[39;49m)\n\u001b[32m    109\u001b[39m     catalog_dir = os.path.join(current_dir, \u001b[33m\"\u001b[39m\u001b[33m..\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpipe_catalogs\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    110\u001b[39m     catalog_dir = os.path.abspath(catalog_dir)\n",
      "\u001b[31mNameError\u001b[39m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "size_hydronic_network(graph,dT_attribute=\"dT_design\",catalog=\"isoplus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def size_hydronic_network(\n",
    "    graph: Any,\n",
    "    m_flow_key = None,\n",
    "    catalog = None,\n",
    "    dT_attribute: str = \"dT_Network\",\n",
    "    network_type: str = \"heating\",\n",
    "    demand_attribute: str = \"input_heat\",\n",
    "    load_scenario: str = \"peak_load\",\n",
    "    cp: float = 4000,\n",
    "    logger: Optional[logging.Logger] = None\n",
    ") -> Any:\n",
    "    \n",
    "    # Set up logger\n",
    "    if logger is None:\n",
    "        logger = set_up_logger(\n",
    "            name=\"hydronic_network_sizing\",\n",
    "            #log_dir=\"./logs\",  # Optional: specify custom directory\n",
    "            level=logging.DEBUG  # INFO level captures all important steps\n",
    "        )\n",
    "\n",
    "    if m_flow_key == None:\n",
    "        # Estimate mass flows\n",
    "        logger.info(f\"Sizing hydronic network: estimating mass flows for {network_type} network with {load_scenario} scenario\")\n",
    "        graph = estimate_m_flow_demand_based(\n",
    "            graph=graph,\n",
    "            network_type=network_type,\n",
    "            demand_attribute=demand_attribute,\n",
    "            load_scenario=load_scenario,\n",
    "            cp=cp,\n",
    "            dT_attribute=dT_attribute,\n",
    "            logger=logger  \n",
    "        )\n",
    "        m_flow_key = f\"m_flow_{load_scenario}\"\n",
    "\n",
    "    logger.info(\"Mass flow estimation completed successfully\")\n",
    "    \n",
    "    # Estimate pipe diameters\n",
    "    logger.info(f\"Sizing hydronic network: estimating pipe diameters for {network_type} network with {load_scenario} scenario\")\n",
    "    if catalog:\n",
    "        df = load_pipe_catalog(catalog)\n",
    "        get_pipe_catalog_DN_m_flow(graph,pipe_catalog=df,logger=logger, mass_flow_key=m_flow_key, dn_key=\"DN\", diameter_key=\"diameter\", robust=True)\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    return graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_pipe_catalog_DN_m_flow(\n",
    "    graph,\n",
    "    pipe_catalog: pd.DataFrame,\n",
    "    logger: logging.Logger,\n",
    "    mass_flow_key: str,\n",
    "    dn_key: str,\n",
    "    diameter_key: str,\n",
    "    robust: bool = True\n",
    ") -> None:\n",
    "    # Collect all edges missing the required mass flow attribute\n",
    "    missing_edges = []\n",
    "    for edge in graph.edges:\n",
    "        if mass_flow_key not in graph.edges[edge]:\n",
    "            missing_edges.append(edge)\n",
    "\n",
    "    if missing_edges:\n",
    "        logger.error(\"The following edges are missing the '%s' attribute:\", mass_flow_key)\n",
    "        for edge in missing_edges:\n",
    "            logger.error(\"  - %s\", edge)\n",
    "        raise ValueError(\n",
    "            f\"Aborting because edges are missing the '{mass_flow_key}' attribute.\"\n",
    "        )\n",
    "\n",
    "    # Update DN and the diameter information for each edge\n",
    "    for edge in graph.edges:\n",
    "        m_flow = graph.edges[edge][mass_flow_key]\n",
    "        matching_rows = pipe_catalog[\n",
    "            (pipe_catalog['mass_flow_min'] <= m_flow) &\n",
    "            (pipe_catalog['mass_flow_max'] >= m_flow)\n",
    "        ]\n",
    "        num_matches = len(matching_rows)\n",
    "\n",
    "        # Scenario 1: No matching row\n",
    "        if num_matches == 0:\n",
    "            if robust:\n",
    "                # Attempt to find the next bigger pipe\n",
    "                bigger_rows = pipe_catalog[pipe_catalog['mass_flow_min'] > m_flow]\n",
    "                if not bigger_rows.empty:\n",
    "                    logger.warning(\n",
    "                        \"Edge %s: No row directly matches mass_flow=%.2f. \"\n",
    "                        \"Using the next bigger pipe.\",\n",
    "                        edge, m_flow\n",
    "                    )\n",
    "                    next_bigger_idx = bigger_rows['mass_flow_min'].idxmin()\n",
    "                    chosen_row = bigger_rows.loc[next_bigger_idx]\n",
    "                else:\n",
    "                    # Fallback: there is no bigger pipe either\n",
    "                    raise ValueError(\n",
    "                        f\"Edge {edge}: No direct match for flow {m_flow}, \"\n",
    "                        \"and no bigger pipe available. Consider extending your pipe catalog.\"\n",
    "                    )\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Edge {edge}: No matching row for flow {m_flow}, and robust=False. \"\n",
    "                    \"Consider adding more pipe entries or adjusting your data.\"\n",
    "                )\n",
    "\n",
    "        # Scenario 2: Exactly one match\n",
    "        elif num_matches == 1:\n",
    "            chosen_row = matching_rows.iloc[0]\n",
    "\n",
    "        # Scenario 3: Multiple matching rows\n",
    "        else:\n",
    "            if robust:\n",
    "                logger.warning(\n",
    "                    \"Edge %s: Multiple matching rows for mass_flow=%.2f. \"\n",
    "                    \"Selecting the row with the largest DN among them.\",\n",
    "                    edge, m_flow\n",
    "                )\n",
    "                max_dn_idx = matching_rows['DN'].idxmax()\n",
    "                chosen_row = matching_rows.loc[max_dn_idx]\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Edge {edge}: Multiple rows match flow {m_flow}, robust=False. \"\n",
    "                    \"Validate pipe catalog ranges for overlaps or remove duplicates.\"\n",
    "                )\n",
    "\n",
    "        dn_value = chosen_row['DN']\n",
    "        diameter_value = float(chosen_row['inner_diameter'])\n",
    "\n",
    "        if dn_key in graph.edges[edge]:\n",
    "            logger.warning(\n",
    "                \"Edge %s already has '%s' set to %s and will be overwritten.\",\n",
    "                edge, dn_key, graph.edges[edge][dn_key]\n",
    "            )\n",
    "        if diameter_key in graph.edges[edge]:\n",
    "            logger.warning(\n",
    "                \"Edge %s already has '%s' set to %s and will be overwritten.\",\n",
    "                edge, diameter_key, graph.edges[edge][diameter_key]\n",
    "            )\n",
    "\n",
    "        graph.edges[edge][dn_key] = dn_value\n",
    "        graph.edges[edge][diameter_key] = diameter_value\n",
    "\n",
    "        logger.info(\n",
    "            \"Edge %s updated: %s=%s, %s=%.2f (mass_flow=%.2f)\",\n",
    "            edge, dn_key, dn_value, diameter_key, diameter_value, m_flow\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_pipe_catalog(catalog_name: str = \"isoplus\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load pipe catalog data from CSV file in the data/pipe_catalogs directory.\n",
    "    \n",
    "    This function loads manufacturer pipe catalog data containing pipe dimensions\n",
    "    and flow capacities for different nominal diameters (DN). The catalog files\n",
    "    are expected to be located in the data/pipe_catalogs subdirectory relative\n",
    "    to the systemmodels module.\n",
    "    \n",
    "    Parameters\n",
    "    ---------- \n",
    "    catalog_name : str, optional\n",
    "        Name of the pipe catalog to load (default: \"isoplus\")\n",
    "        The function will look for a file named \"{catalog_name}.csv\"\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame containing pipe catalog data with columns:\n",
    "        - DN: Nominal diameter [mm]\n",
    "        - wall_thickness: Pipe wall thickness [mm] \n",
    "        - inner_diameter: Inner pipe diameter [mm]\n",
    "        - mass_flow_min: Minimum mass flow capacity [t/h]\n",
    "        - mass_flow_max: Maximum mass flow capacity [t/h]\n",
    "        \n",
    "    Raises\n",
    "    ------\n",
    "    FileNotFoundError\n",
    "        If the specified catalog file does not exist\n",
    "    ValueError\n",
    "        If the catalog file exists but contains invalid data structure\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> catalog = load_pipe_catalog(\"isoplus\")\n",
    "    >>> print(catalog.columns.tolist())\n",
    "    ['DN', 'wall_thickness', 'inner_diameter', 'mass_flow_min', 'mass_flow_max']\n",
    "    \n",
    "    >>> # Load different catalog (if available)\n",
    "    >>> rehau_catalog = load_pipe_catalog(\"rehau\")\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    The CSV files can contain comment lines starting with '#' which will be\n",
    "    automatically ignored during loading. This allows for metadata and source\n",
    "    information to be stored directly in the catalog files.\n",
    "    \n",
    "    The function expects the catalog files to be located at:\n",
    "    {module_directory}/uesgraphs/data/pipe_catalogs/{catalog_name}.csv\n",
    "    \"\"\"\n",
    "    # Construct path to catalog file relative to this module\n",
    "    #current_dir = os.path.dirname(__file__)\n",
    "    current_dir = os.getcwd()  # Get the current working directory\n",
    "    catalog_path = os.path.join(\n",
    "        current_dir, \n",
    "        \"..\", \n",
    "        \"data\", \n",
    "        \"pipe_catalogs\", \n",
    "        f\"{catalog_name}.csv\"\n",
    "    )\n",
    "    \n",
    "    # Convert to absolute path for better error reporting\n",
    "    catalog_path = os.path.abspath(catalog_path)\n",
    "    \n",
    "    # Check if catalog file exists\n",
    "    if not os.path.isfile(catalog_path):\n",
    "        available_catalogs = _get_available_catalogs()\n",
    "        raise FileNotFoundError(\n",
    "            f\"Pipe catalog '{catalog_name}' not found at: {catalog_path}\\n\"\n",
    "            f\"Available catalogs: {available_catalogs}\"\n",
    "        )\n",
    "    \n",
    "    try:\n",
    "        # Load CSV data, ignoring comment lines starting with '#'\n",
    "        catalog_df = pd.read_csv(catalog_path, comment='#')\n",
    "        \n",
    "        # Validate required columns exist\n",
    "        required_columns = ['DN', 'inner_diameter', 'mass_flow_min', 'mass_flow_max']\n",
    "        missing_columns = [col for col in required_columns if col not in catalog_df.columns]\n",
    "        \n",
    "        if missing_columns:\n",
    "            raise ValueError(\n",
    "                f\"Catalog '{catalog_name}' is missing required columns: {missing_columns}\\n\"\n",
    "                f\"Available columns: {catalog_df.columns.tolist()}\"\n",
    "            )\n",
    "        \n",
    "        # Sort by DN for consistent ordering\n",
    "        catalog_df = catalog_df.sort_values('inner_diameter').reset_index(drop=True)\n",
    "        \n",
    "        return catalog_df\n",
    "        \n",
    "    except pd.errors.EmptyDataError:\n",
    "        raise ValueError(f\"Catalog file '{catalog_name}' is empty or contains no valid data\")\n",
    "    except pd.errors.ParserError as e:\n",
    "        raise ValueError(f\"Error parsing catalog file '{catalog_name}': {str(e)}\")\n",
    "\n",
    "\n",
    "def _get_available_catalogs() -> list:\n",
    "    \"\"\"\n",
    "    Get list of available pipe catalog files.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        List of available catalog names (without .csv extension)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        current_dir = os.path.dirname(__file__)\n",
    "        catalog_dir = os.path.join(current_dir, \"..\", \"data\", \"pipe_catalogs\")\n",
    "        catalog_dir = os.path.abspath(catalog_dir)\n",
    "        \n",
    "        if not os.path.isdir(catalog_dir):\n",
    "            return []\n",
    "            \n",
    "        # Get all CSV files in catalog directory\n",
    "        csv_files = [f for f in os.listdir(catalog_dir) if f.endswith('.csv')]\n",
    "        # Remove .csv extension to get catalog names\n",
    "        catalog_names = [os.path.splitext(f)[0] for f in csv_files]\n",
    "        \n",
    "        return sorted(catalog_names)\n",
    "        \n",
    "    except (OSError, IOError):\n",
    "        return []\n",
    "\n",
    "\n",
    "def get_catalog_info(catalog_name: str = \"isoplus\") -> dict:\n",
    "    \"\"\"\n",
    "    Get basic information about a pipe catalog.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    catalog_name : str, optional\n",
    "        Name of the pipe catalog (default: \"isoplus\")\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary containing catalog information:\n",
    "        - name: Catalog name\n",
    "        - num_sizes: Number of available pipe sizes\n",
    "        - dn_range: Tuple of (min_DN, max_DN)\n",
    "        - flow_range: Tuple of (min_flow, max_flow) in t/h\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> info = get_catalog_info(\"isoplus\")\n",
    "    >>> print(f\"Catalog has {info['num_sizes']} pipe sizes\")\n",
    "    >>> print(f\"DN range: {info['dn_range'][0]} - {info['dn_range'][1]} mm\")\n",
    "    \"\"\"\n",
    "    catalog_df = load_pipe_catalog(catalog_name)\n",
    "    \n",
    "    return {\n",
    "        'name': catalog_name,\n",
    "        'num_sizes': len(catalog_df),\n",
    "        'dn_range': (catalog_df['DN'].min(), catalog_df['DN'].max()),\n",
    "        'flow_range': (catalog_df['mass_flow_min'].min(), catalog_df['mass_flow_max'].max()),\n",
    "        'diameter_range': (catalog_df['inner_diameter'].min(), catalog_df['inner_diameter'].max())\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'updated_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m edges = \u001b[38;5;28mlist\u001b[39m(\u001b[43mupdated_graph\u001b[49m.edges)\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m edge \u001b[38;5;129;01min\u001b[39;00m edges:\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00medge[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00medge[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mupdated_graph.edges[edge][\u001b[33m\"\u001b[39m\u001b[33mm_flow_peak_load\u001b[39m\u001b[33m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m m3/h\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'updated_graph' is not defined"
     ]
    }
   ],
   "source": [
    "edges = list(updated_graph.edges)\n",
    "for edge in edges:\n",
    "    print(f\"{edge[0]} {edge[1]} with {updated_graph.edges[edge][\"m_flow_peak_load\"]} m3/h\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_up_logger(name, log_dir=None, level=int(logging.INFO)):  # Changed to INFO for more details\n",
    "    \"\"\"\n",
    "    Set up a file-based logger with timestamp and detailed formatting.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    name : str\n",
    "        Logger name, used for log file naming\n",
    "    log_dir : str, optional\n",
    "        Directory for log files. If None, uses system temp directory\n",
    "    level : int, optional\n",
    "        Logging level (default: INFO for detailed mass flow logging)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    logging.Logger\n",
    "        Configured logger instance writing to timestamped file\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(level)\n",
    "    \n",
    "    # Determine log directory\n",
    "    if log_dir is None:\n",
    "        log_dir = tempfile.gettempdir()\n",
    "    \n",
    "    # Create timestamped log file\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    log_file = os.path.join(log_dir, f\"{name}_{timestamp}.log\")\n",
    "    print(f\"Logfile findable here: {log_file}\")\n",
    "    \n",
    "    # Configure file handler with detailed formatting\n",
    "    handler = logging.FileHandler(log_file)\n",
    "    formatter = logging.Formatter(\n",
    "        '%(asctime)s - %(name)s - [%(filename)s:%(lineno)d] - %(levelname)s - %(message)s'\n",
    "    )\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    \n",
    "    return logger\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def estimate_m_flow_demand_based(\n",
    "    graph: Any,\n",
    "    network_type: str = \"heating\",\n",
    "    demand_attribute: str = \"input_heat\",\n",
    "    load_scenario: str = \"peak_load\",\n",
    "    cp: float = 4000,\n",
    "    dT_attribute: str = \"dT_Network\",\n",
    "    logger: Optional[logging.Logger] = None\n",
    ") -> Any:\n",
    "    \"\"\"\n",
    "    Estimates mass flow for each edge by calculating flows at demand nodes and propagating backwards.\n",
    "    \n",
    "    This function implements a physically correct approach where mass flows are calculated\n",
    "    at each demand node based on their specific load and temperature difference, then\n",
    "    aggregated backwards through the network following mass conservation principles.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : UESGraph or nx.Graph\n",
    "        The graph representing the network with nodelist_building attribute.\n",
    "    network_type : str, optional\n",
    "        Type of network, default is \"heating\". Must be \"heating\" or \"cooling\".\n",
    "    demand_attribute : str, optional\n",
    "        Attribute name containing load values in demand nodes, default is \"input_heat\".\n",
    "    load_scenario : str, optional\n",
    "        Load scenario for calculation, default is \"peak_load\".\n",
    "        Options: \"peak_load\" (maximum value) or \"average_load\" (mean value).\n",
    "    cp : float, optional\n",
    "        Specific heat capacity of the fluid in J/(kg*K), default is 4000.\n",
    "    dT_attribute : str\n",
    "        Node attribute name for temperature difference values in Kelvin.\n",
    "        Must be present in all demand nodes with positive numeric values.\n",
    "        Used for individual mass flow calculations at each demand node.\n",
    "    logger : logging.Logger, optional\n",
    "        Logger instance for logging messages. If None, creates a default logger.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    graph : UESGraph or nx.Graph\n",
    "        Input graph with additional edge attributes:\n",
    "        - m_flow_{load_scenario}: Mass flow rate in kg/s for each edge\n",
    "        - contributing_demands_{load_scenario}: List of demand nodes contributing to edge flow\n",
    "        - supply_attribution_{load_scenario}: Dictionary showing which supply serves which demands\n",
    "        \n",
    "    Raises\n",
    "    ------\n",
    "    TypeError\n",
    "        If graph does not have required nodelist_building attribute.\n",
    "    ValueError\n",
    "        If network_type or load_scenario parameters are invalid.\n",
    "        If no supply or demand nodes are found.\n",
    "        If required node attributes are missing.\n",
    "    \"\"\"\n",
    "    # Initialize logger\n",
    "    if logger is None:\n",
    "        logger = logging.getLogger(__name__)\n",
    "    \n",
    "    # Validate input parameters\n",
    "    _validate_parameters(graph, network_type, load_scenario, demand_attribute)\n",
    "    \n",
    "    # Step 1: Identify and categorize nodes\n",
    "    supply_nodes, demand_nodes = _identify_network_nodes(\n",
    "        graph, network_type, demand_attribute, logger\n",
    "    )\n",
    "    \n",
    "    # Step 2: Calculate mass flows at demand nodes\n",
    "    demand_mass_flows = _calculate_demand_mass_flows(\n",
    "        graph, demand_nodes, demand_attribute, load_scenario, cp, dT_attribute, logger\n",
    "    )\n",
    "    \n",
    "    # Step 3: Build supply-to-demand flow paths\n",
    "    supply_demand_paths = _build_flow_paths(\n",
    "        graph, supply_nodes, demand_nodes, logger\n",
    "    )\n",
    "    \n",
    "   # Step 4: Aggregate mass flows on edges using maximum principle\n",
    "    _aggregate_edge_flows_robust(\n",
    "        graph, supply_demand_paths, demand_mass_flows, load_scenario, logger\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Successfully calculated mass flows for {len(graph.edges)} edges \"\n",
    "               f\"using demand-based approach with {load_scenario} scenario\")\n",
    "    \n",
    "    return graph\n",
    "\n",
    "\n",
    "def _validate_parameters(\n",
    "    graph: Any, \n",
    "    network_type: str, \n",
    "    load_scenario: str, \n",
    "    demand_attribute: str\n",
    ") -> None:\n",
    "    \"\"\"Validate input parameters for the mass flow estimation function.\"\"\"\n",
    "    if not hasattr(graph, \"nodelist_building\"):\n",
    "        raise TypeError(\"Graph must be a UESGraph object with nodelist_building attribute\")\n",
    "    \n",
    "    if network_type not in [\"heating\", \"cooling\"]:\n",
    "        raise ValueError(\"network_type must be 'heating' or 'cooling'\")\n",
    "    \n",
    "    if load_scenario not in [\"peak_load\", \"average_load\"]:\n",
    "        raise ValueError(\"load_scenario must be 'peak_load' or 'average_load'\")\n",
    "\n",
    "\n",
    "def _identify_network_nodes(\n",
    "    graph: Any, \n",
    "    network_type: str, \n",
    "    demand_attribute: str, \n",
    "    logger: logging.Logger\n",
    ") -> Tuple[List[Any], List[Any]]:\n",
    "    \"\"\"\n",
    "    Identify and categorize supply and demand nodes in the network.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (supply_nodes, demand_nodes) - Lists of supply and demand node identifiers\n",
    "    \"\"\"\n",
    "    supply_nodes = []\n",
    "    demand_nodes = []\n",
    "    supply_attr = f\"is_supply_{network_type}\"\n",
    "    \n",
    "    for node in graph.nodelist_building:\n",
    "        # Check for required supply attribute\n",
    "        if supply_attr not in graph.nodes[node]:\n",
    "            raise ValueError(f\"Node {node} missing required attribute '{supply_attr}'\")\n",
    "        \n",
    "        if graph.nodes[node][supply_attr]:\n",
    "            supply_nodes.append(node)\n",
    "        else:\n",
    "            # Validate demand node has required load attribute\n",
    "            if demand_attribute not in graph.nodes[node]:\n",
    "                raise ValueError(f\"Demand node {node} missing required attribute '{demand_attribute}'\")\n",
    "            demand_nodes.append(node)\n",
    "    \n",
    "    # Ensure we have both supply and demand nodes\n",
    "    if not supply_nodes:\n",
    "        raise ValueError(f\"No supply nodes found for network type '{network_type}'\")\n",
    "    if not demand_nodes:\n",
    "        raise ValueError(f\"No demand nodes found for network type '{network_type}'\")\n",
    "    \n",
    "    logger.info(f\"Identified {len(supply_nodes)} supply nodes and {len(demand_nodes)} demand nodes\")\n",
    "    return supply_nodes, demand_nodes\n",
    "\n",
    "\n",
    "def _calculate_demand_mass_flows(\n",
    "    graph: Any,\n",
    "    demand_nodes: List[Any],\n",
    "    demand_attribute: str,\n",
    "    load_scenario: str,\n",
    "    cp: float,\n",
    "    dT_attribute: str,\n",
    "    logger: logging.Logger\n",
    ") -> Dict[Any, float]:\n",
    "    \"\"\"\n",
    "    Calculate mass flow requirements at each demand node.\n",
    "    \n",
    "    This function processes each demand node individually, calculating the required\n",
    "    mass flow based on the node's load and temperature difference (dT).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : UESGraph or nx.Graph\n",
    "        Network graph containing node data\n",
    "    demand_nodes : List[Any]\n",
    "        List of demand node identifiers\n",
    "    demand_attribute : str\n",
    "        Attribute name containing load values\n",
    "    load_scenario : str\n",
    "        Either \"peak_load\" or \"average_load\"\n",
    "    cp : float\n",
    "        Specific heat capacity in J/(kg*K)\n",
    "    dT_attribute : str\n",
    "        Node attribute name for temperature difference values in Kelvin.\n",
    "        Must be present in all demand nodes with positive numeric values.\n",
    "        Used for individual mass flow calculations at each demand node.\n",
    "    logger : logging.Logger\n",
    "        Logger for status messages\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Dict[Any, float]\n",
    "        Dictionary mapping demand node identifiers to their mass flow requirements in kg/s\n",
    "    \"\"\"\n",
    "    \n",
    "    for demand_node in demand_nodes:\n",
    "        if dT_attribute not in graph.nodes[demand_node]:\n",
    "            # Get available attributes for better error message\n",
    "            available_attrs = list(graph.nodes[demand_node].keys())\n",
    "            dT_related_attrs = [attr for attr in available_attrs if 'dT' in attr or 'delta' in attr.lower() or 'temp' in attr.lower()]\n",
    "\n",
    "            error_msg = (\n",
    "                f\"Demand node '{demand_node}' is missing the required temperature difference attribute '{dT_attribute}'. \"\n",
    "                f\"This attribute must contain the temperature difference (dT) in Kelvin between supply and return flow \"\n",
    "                f\"for mass flow calculation (formula: m_flow = thermal_load / (cp * dT)).\\n\\n\"\n",
    "                f\"To fix this issue:\\n\"\n",
    "                f\"1. Add '{dT_attribute}' attribute to node '{demand_node}' with a numeric value in Kelvin\\n, like with graph.nodes[{demand_node}]['{dT_attribute}'] = 30\\n\"\n",
    "                f\"2. Or specify a different attribute name using the 'dT_attribute' parameter\\n\"\n",
    "            )\n",
    "\n",
    "            if dT_related_attrs:\n",
    "                error_msg += f\"\\nConsider using: dT_attribute='{dT_related_attrs[0]}' if appropriate, when calling method\"\n",
    "\n",
    "            raise ValueError(error_msg)\n",
    "        \n",
    "    demand_mass_flows = {}\n",
    "    \n",
    "    for demand_node in demand_nodes:\n",
    "        # Extract load values from node attribute\n",
    "        load_values = graph.nodes[demand_node][demand_attribute]\n",
    "        \n",
    "        # Handle both single values and lists\n",
    "        if isinstance(load_values, (int, float)):\n",
    "            load_values = [load_values]\n",
    "        \n",
    "        # Convert to absolute values for calculation\n",
    "        abs_load_values = [abs(x) for x in load_values]\n",
    "        \n",
    "        # Calculate load based on scenario\n",
    "        if load_scenario == \"peak_load\":\n",
    "            load = max(abs_load_values)\n",
    "        elif load_scenario == \"average_load\":\n",
    "            load = sum(abs_load_values) / len(abs_load_values)\n",
    "        \n",
    "        # Get node-specific temperature difference\n",
    "        node_dT = graph.nodes[demand_node][dT_attribute]\n",
    "        # Validate dT value\n",
    "        if not isinstance(node_dT, (int, float)) or node_dT <= 0:\n",
    "            raise ValueError(\n",
    "                f\"Temperature difference (dT) for demand node '{demand_node}' must be a positive number, \"\n",
    "                f\"got {node_dT} (type: {type(node_dT).__name__})\"\n",
    "            )\n",
    "\n",
    "        # Calculate mass flow: m_flow = Q / (cp * dT)\n",
    "        mass_flow = load / (cp * node_dT)\n",
    "        demand_mass_flows[demand_node] = mass_flow\n",
    "        \n",
    "        logger.debug(f\"Demand node {demand_node}: load={load:.2f}W, dT={node_dT}K, \"\n",
    "                    f\"m_flow={mass_flow:.6f}kg/s\")\n",
    "    \n",
    "    \n",
    "    total_demand_flow = sum(demand_mass_flows.values())\n",
    "    logger.info(f\"Calculated mass flows for {len(demand_nodes)} demand nodes, \"\n",
    "               f\"total demand: {total_demand_flow:.6f} kg/s\")\n",
    "    \n",
    "    return demand_mass_flows\n",
    "\n",
    "def _build_flow_paths(\n",
    "    graph: Any,\n",
    "    supply_nodes: List[Any],\n",
    "    demand_nodes: List[Any],\n",
    "    logger: logging.Logger\n",
    ") -> Dict[Tuple[Any, Any], List[Tuple[Any, Any]]]:\n",
    "    \"\"\"\n",
    "    Build flow paths from each supply node to reachable demand nodes.\n",
    "    \n",
    "    This function identifies all supply-demand pairs that are connected and\n",
    "    determines the shortest path between them, converting paths to edge lists.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : UESGraph or nx.Graph\n",
    "        Network graph\n",
    "    supply_nodes : List[Any]\n",
    "        List of supply node identifiers\n",
    "    demand_nodes : List[Any]\n",
    "        List of demand node identifiers\n",
    "    logger : logging.Logger\n",
    "        Logger for status messages\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Dict[Tuple[Any, Any], List[Tuple[Any, Any]]]\n",
    "        Dictionary mapping (supply, demand) tuples to lists of edges in the flow path\n",
    "    \"\"\"\n",
    "    supply_demand_paths = {}\n",
    "    unreachable_demands = set(demand_nodes)  # Track which demands are reachable\n",
    "    \n",
    "    for supply in supply_nodes:\n",
    "        reachable_from_this_supply = []\n",
    "        \n",
    "        for demand in demand_nodes:\n",
    "            try:\n",
    "                if nx.has_path(graph, supply, demand):\n",
    "                    # Calculate shortest path and convert to edge list\n",
    "                    node_path = nx.shortest_path(graph, supply, demand)\n",
    "                    edge_path = [(node_path[i], node_path[i + 1]) \n",
    "                                for i in range(len(node_path) - 1)]\n",
    "                    \n",
    "                    supply_demand_paths[(supply, demand)] = edge_path\n",
    "                    reachable_from_this_supply.append(demand)\n",
    "                    \n",
    "                    # Remove from unreachable set\n",
    "                    unreachable_demands.discard(demand)\n",
    "                    \n",
    "            except nx.NetworkXNoPath:\n",
    "                # Explicitly handle case where no path exists\n",
    "                continue\n",
    "        \n",
    "        logger.debug(f\"Supply {supply} can reach {len(reachable_from_this_supply)} demands: \"\n",
    "                    f\"{reachable_from_this_supply}\")\n",
    "    \n",
    "    # Log summary information\n",
    "    total_paths = len(supply_demand_paths)\n",
    "    logger.info(f\"Built {total_paths} supply-to-demand flow paths\")\n",
    "    \n",
    "    if unreachable_demands:\n",
    "        logger.warning(f\"Unreachable demand nodes found: {list(unreachable_demands)}\")\n",
    "    \n",
    "    return supply_demand_paths\n",
    "\n",
    "def _aggregate_edge_flows_robust(\n",
    "    graph: Any,\n",
    "    supply_demand_paths: Dict[Tuple[Any, Any], List[Tuple[Any, Any]]],\n",
    "    demand_mass_flows: Dict[Any, float],\n",
    "    load_scenario: str,\n",
    "    logger: logging.Logger\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Aggregate mass flows on edges using a robust supply-based approach with maximum flow principle.\n",
    "    \n",
    "    This function implements a two-stage aggregation process:\n",
    "    1. For each supply node, calculate cumulative flows on all edges serving its connected demands\n",
    "    2. Apply maximum flow principle when multiple supplies can serve the same edge\n",
    "    \n",
    "    This approach ensures robust network sizing where each edge is dimensioned for the worst-case\n",
    "    scenario among all possible supply configurations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : UESGraph or nx.Graph\n",
    "        Network graph to be modified with calculated flow data\n",
    "    supply_demand_paths : Dict[Tuple[Any, Any], List[Tuple[Any, Any]]]\n",
    "        Mapping of (supply, demand) pairs to their corresponding edge paths\n",
    "    demand_mass_flows : Dict[Any, float]\n",
    "        Mass flow requirements for each demand node in kg/s\n",
    "    load_scenario : str\n",
    "        Load scenario identifier used for attribute naming in the graph\n",
    "    logger : logging.Logger\n",
    "        Logger instance for progress and summary information\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting robust edge flow aggregation using supply-based approach\")\n",
    "    \n",
    "    # Initialize data structures for supply-based flow tracking\n",
    "    supply_edge_flows = {}  # {supply_node: {edge: accumulated_flow}}\n",
    "    edge_contributing_demands = {}  # {edge: set_of_demand_nodes}\n",
    "    supply_attribution = {}  # {demand_node: supply_node}\n",
    "    \n",
    "    # Step 1: Group supply-demand paths by supply node for separate processing\n",
    "    supplies = set(supply for supply, demand in supply_demand_paths.keys())\n",
    "    logger.info(f\"Processing flows for {len(supplies)} supply nodes\")\n",
    "    \n",
    "    # Step 2: Calculate aggregated flows for each supply node independently\n",
    "    for supply in supplies:\n",
    "        supply_edge_flows[supply] = {}\n",
    "        demands_served = []\n",
    "        \n",
    "        logger.debug(f\"Processing supply node: {supply}\")\n",
    "        \n",
    "        # Process all demand nodes served by this supply\n",
    "        for (sup, demand), edge_path in supply_demand_paths.items():\n",
    "            if sup == supply:\n",
    "                demand_flow = demand_mass_flows[demand]\n",
    "                demands_served.append(demand)\n",
    "                \n",
    "                # Record supply attribution for this demand\n",
    "                supply_attribution[demand] = supply\n",
    "                \n",
    "                # Accumulate demand flow along the entire path to this demand\n",
    "                for edge in edge_path:\n",
    "                    # Add flow to supply-specific edge flow tracking\n",
    "                    if edge in supply_edge_flows[supply]:\n",
    "                        supply_edge_flows[supply][edge] += demand_flow\n",
    "                    else:\n",
    "                        supply_edge_flows[supply][edge] = demand_flow\n",
    "                    \n",
    "                    # Track which demands contribute to each edge for documentation\n",
    "                    if edge not in edge_contributing_demands:\n",
    "                        edge_contributing_demands[edge] = set()\n",
    "                    edge_contributing_demands[edge].add(demand)\n",
    "        \n",
    "        total_supply_flow = sum(demand_mass_flows[d] for d in demands_served)\n",
    "        logger.debug(f\"Supply {supply}: serves {len(demands_served)} demands, \"\n",
    "                    f\"total flow = {total_supply_flow:.6f} kg/s\")\n",
    "    \n",
    "    logger.debug(f\"Identified flows: {supply_edge_flows}\")\n",
    "\n",
    "    # Step 3: Apply maximum flow principle across all supplies for robust sizing\n",
    "    logger.info(\"Applying maximum flow principle across supplies for robust edge sizing\")\n",
    "    final_edge_flows = {}\n",
    "    supply_conflicts = {}  # Track edges with multiple supply options\n",
    "    \n",
    "    for supply, edge_flows in supply_edge_flows.items():\n",
    "        for edge, flow in edge_flows.items():\n",
    "            # Normalize edge representation for consistent dictionary access\n",
    "            normalized_edge = __normalize_edge(edge)\n",
    "            logger.debug(f\"Processing edge {edge} with flow {flow:.6f} kg/s from supply {supply}\")\n",
    "            if normalized_edge  in final_edge_flows:\n",
    "                # Multiple supplies can serve this edge - apply maximum principle\n",
    "                if normalized_edge  not in supply_conflicts:\n",
    "                    supply_conflicts[normalized_edge ] = []\n",
    "                supply_conflicts[normalized_edge ].append((supply, flow))\n",
    "                \n",
    "                # Update to maximum flow value for robust design\n",
    "                final_edge_flows[normalized_edge ] = max(final_edge_flows[normalized_edge ], flow)\n",
    "            else:\n",
    "                # First supply to use this edge\n",
    "                final_edge_flows[normalized_edge ] = flow\n",
    "    \n",
    "    # Log information about supply conflicts and robust sizing decisions\n",
    "    if supply_conflicts:\n",
    "        logger.info(f\"Applied maximum flow principle to {len(supply_conflicts)} edges \"\n",
    "                   f\"with multiple supply options\")\n",
    "        for edge, conflicts in supply_conflicts.items():\n",
    "            flows = [f\"{supply}: {flow:.6f}\" for supply, flow in conflicts]\n",
    "            max_flow = final_edge_flows[edge]\n",
    "            logger.debug(f\"Edge {edge} - Supplies: [{', '.join(flows)}] → \"\n",
    "                        f\"Selected: {max_flow:.6f} kg/s\")\n",
    "    \n",
    "    # Step 4: Apply calculated flows to all graph edges\n",
    "    edges_with_flow = 0\n",
    "    edges_without_flow = 0\n",
    "    \n",
    "    for edge in graph.edges:\n",
    "        # Normalize the current graph edge for dictionary lookup\n",
    "        normalized_edge = __normalize_edge(edge)\n",
    "        if normalized_edge in final_edge_flows:\n",
    "            # Set mass flow attribute for edges with calculated flows\n",
    "            graph.edges[normalized_edge][f\"m_flow_{load_scenario}\"] = final_edge_flows[normalized_edge]\n",
    "            \n",
    "            \n",
    "            edges_with_flow += 1\n",
    "        else:\n",
    "            logger.warning(f\"Edge {edge} has no flow assigned, setting to 0.0 kg/s\")\n",
    "            # Initialize edges without flow (not part of any supply-demand path)\n",
    "            graph.edges[normalized_edge][f\"m_flow_{load_scenario}\"] = 0.0\n",
    "            graph.edges[normalized_edge][f\"contributing_demands_{load_scenario}\"] = []\n",
    "            edges_without_flow += 1\n",
    "    \n",
    "    # Step 5: Store supply attribution information at graph level for reference\n",
    "    graph.graph[f\"supply_attribution_{load_scenario}\"] = supply_attribution\n",
    "    \n",
    "    # Step 6: Calculate and log comprehensive summary statistics\n",
    "    total_demand_flow = sum(demand_mass_flows.values())\n",
    "    active_edges_flow = sum(final_edge_flows.values()) if final_edge_flows else 0.0\n",
    "    \n",
    "    logger.info(f\"Flow aggregation completed successfully:\")\n",
    "    logger.info(f\"  - Total demand flow: {total_demand_flow:.6f} kg/s\")\n",
    "    logger.info(f\"  - Edges with flow: {edges_with_flow}/{len(graph.edges)}\")\n",
    "    logger.info(f\"  - Edges without flow: {edges_without_flow}\")\n",
    "    logger.info(f\"  - Supply-demand pairs processed: {len(supply_demand_paths)}\")\n",
    "    \n",
    "    # Log flow distribution statistics for active edges\n",
    "    if final_edge_flows:\n",
    "        max_edge_flow = max(final_edge_flows.values())\n",
    "        min_edge_flow = min(final_edge_flows.values())\n",
    "        avg_edge_flow = sum(final_edge_flows.values()) / len(final_edge_flows)\n",
    "        \n",
    "        logger.info(f\"Active edge flow statistics:\")\n",
    "        logger.info(f\"  - Maximum edge flow: {max_edge_flow:.6f} kg/s\")\n",
    "        logger.info(f\"  - Minimum edge flow: {min_edge_flow:.6f} kg/s\")\n",
    "        logger.info(f\"  - Average edge flow: {avg_edge_flow:.6f} kg/s\")\n",
    "    \n",
    "    logger.info(\"Robust edge flow aggregation completed successfully\")\n",
    "\n",
    "def __normalize_edge(edge):\n",
    "    \"\"\"\n",
    "    Normalize edge tuple to consistent order for undirected graph operations.\n",
    "    \n",
    "    This function ensures that edges (A, B) and (B, A) are treated as the same edge\n",
    "    by always returning the tuple with the smaller node ID first.\n",
    "    \n",
    "    Args:\n",
    "        edge (tuple): Edge as (node1, node2)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Normalized edge as (min_node, max_node)\n",
    "    \"\"\"\n",
    "    return tuple(sorted(edge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "from typing import Any, List, Optional, Dict\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "def estimate_m_flow(\n",
    "    graph: Any,\n",
    "    dT: Optional[float] = None,\n",
    "    network_type: str = \"heating\",\n",
    "    demand_attribute: str = \"input_heat\",\n",
    "    load_scenario: str = \"peak_load\",\n",
    "    cp: float = 4000,\n",
    "    logger: Optional[logging.Logger] = None\n",
    ") -> Any:\n",
    "    \"\"\"\n",
    "    Estimates the mass flow for each edge in the graph based on building loads.\n",
    "    \n",
    "    This function calculates the maximum load for each edge in the graph based on\n",
    "    the shortest path from producer to consumer nodes and then calculates the\n",
    "    mass flow for each edge based on the maximum load.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : UESGraph or nx.Graph\n",
    "        The graph representing the network.\n",
    "    dT : float, optional\n",
    "        Temperature difference between supply and return in K.\n",
    "        If None, will attempt to read from demand nodes' 'dT_Network' attribute.\n",
    "    network_type : str, optional\n",
    "        Type of network, default is \"heating\".\n",
    "    demand_attribute : str, optional\n",
    "        Key for the load in the node attributes, default is \"input_heat\".\n",
    "    load_scenario : str, optional\n",
    "        Load scenario, default is \"peak_load\". Can be \"peak_load\" or \"average_load\".\n",
    "    cp : float, optional\n",
    "        Specific heat capacity of the fluid in J/(kg*K), default is 4000.\n",
    "    logger : logging.Logger, optional\n",
    "        Logger to use for logging messages. If None, creates a new logger.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    graph : UESGraph or nx.Graph\n",
    "        The input graph with additional edge attributes:\n",
    "        - load_{load_scenario}: Maximum load for the edge\n",
    "        - load_{load_scenario}_supplies: Dictionary with loads for each producer\n",
    "        - m_flow_{load_scenario}: Mass flow for the edge\n",
    "        \n",
    "    Raises\n",
    "    ------\n",
    "    TypeError\n",
    "        If graph is not a UESGraph object with nodelist_building attribute.\n",
    "    ValueError\n",
    "        If network_type is not 'heating' or 'cooling'.\n",
    "        If load_scenario is not 'peak_load' or 'average_load'.\n",
    "        If no producer or consumer nodes are found.\n",
    "        If dT is not provided and cannot be determined from node attributes.\n",
    "    \"\"\"\n",
    "    # Set up logger\n",
    "    if logger is None:\n",
    "        logger = logging.getLogger(__name__)\n",
    "    \n",
    "    # Validate parameters\n",
    "    if not hasattr(graph, \"nodelist_building\"):\n",
    "        raise TypeError(\"graph must be a UESGraph object with nodelist_building attribute\")\n",
    "    \n",
    "    if network_type not in [\"heating\", \"cooling\"]:\n",
    "        raise ValueError(\"network_type must be 'heating' or 'cooling'\")\n",
    "    \n",
    "    if load_scenario not in [\"peak_load\", \"average_load\"]:\n",
    "        raise ValueError(\"load_scenario must be 'peak_load' or 'average_load'\")\n",
    "    \n",
    "    # Find consumer and producer nodes\n",
    "    demands = []\n",
    "    supplies = []\n",
    "    dT_node_values = {}  # Dictionary to store dT values for each demand node\n",
    "\n",
    "    for node in graph.nodelist_building:\n",
    "        supply_attr = f\"is_supply_{network_type}\"\n",
    "        if supply_attr not in graph.nodes[node]:\n",
    "            raise ValueError(f\"Node {node} does not have attribute '{supply_attr}'\")\n",
    "        \n",
    "        if graph.nodes[node][supply_attr]:\n",
    "            supplies.append(node)\n",
    "        else:\n",
    "            if demand_attribute not in graph.nodes[node]:\n",
    "                raise ValueError(f\"Node {node} does not have attribute '{demand_attribute}'\")\n",
    "            demands.append(node)\n",
    "            \n",
    "            # Collect dT values from demand nodes if available\n",
    "            if dT is None and 'dT_Network' in graph.nodes[node]:\n",
    "                dT_node_values[node] = graph.nodes[node]['dT_Network']\n",
    "    \n",
    "    if not supplies:\n",
    "        raise ValueError(f\"No producer nodes found for network type '{network_type}'\")\n",
    "    \n",
    "    if not demands:\n",
    "        raise ValueError(f\"No consumer nodes found for network type '{network_type}'\")\n",
    "    \n",
    "    # Determine global dT or flag for node-specific usage\n",
    "    use_node_specific_dT = False\n",
    "\n",
    "    # Determine temperature difference (dT)\n",
    "    if dT is not None:\n",
    "        # Use the explicitly provided dT parameter\n",
    "        logger.info(f\"Using provided dT value: {dT} K\")\n",
    "    elif dT_node_values:\n",
    "        # We have dT values from nodes, but need to decide how to use them\n",
    "        if len(set(dT_node_values.values())) == 1:\n",
    "             # All nodes have the same dT value, so use that\n",
    "            dT = next(iter(dT_node_values.values()))\n",
    "            logger.info(f\"Using uniform dT={dT} K from all demand nodes\")\n",
    "        elif  len(dT_node_values) == len(demands):\n",
    "            use_node_specific_dT = True\n",
    "            # Nodes have different dT values - we'll use node-specific values later\n",
    "            logger.info(f\"Using node-specific dT values from demand nodes\")\n",
    "        else:\n",
    "            # Some nodes have dT values, but not all - use the average\n",
    "            dT = sum(dT_node_values.values()) / len(dT_node_values)\n",
    "            logger.info(f\"Using average dT={dT} K from demand nodes\")\n",
    "           \n",
    "    elif hasattr(graph, \"graph\") and \"dT_design\" in graph.graph:\n",
    "        # Fallback to deprecated attribute\n",
    "        dT = graph.graph[\"dT_design\"]\n",
    "        warnings.warn(\n",
    "            \"'dT_design' attribute is deprecated. Use 'dT_Network' in demand nodes instead.\",\n",
    "            DeprecationWarning\n",
    "        )\n",
    "        logger.warning(f\"Using deprecated 'dT_design' attribute: {dT} K\")\n",
    "    else:\n",
    "        # Last resort: default value with warning\n",
    "        dT = 20.0  # Common default for heating networks\n",
    "        warnings.warn(\n",
    "            f\"No dT specified. Using default value of {dT} K. \"\n",
    "            \"Specify dT explicitly or add 'dT_Network' to demand nodes.\",\n",
    "            UserWarning\n",
    "        )\n",
    "        logger.warning(f\"No dT specified. Using default value of {dT} K\")\n",
    "    \n",
    "    logger.info(f\"Estimating mass flows for {network_type} network with {load_scenario} scenario (dT={dT}K)\")\n",
    "    \n",
    "    # Calculate loads for edges\n",
    "    edges_loads = {}\n",
    "    \n",
    "    for supply in supplies:\n",
    "        for demand in demands:\n",
    "            if nx.has_path(graph, supply, demand):\n",
    "                # Calculate load for the consumer node\n",
    "                load_values = [abs(x) for x in graph.nodes[demand][demand_attribute]]\n",
    "                \n",
    "                if load_scenario == \"peak_load\":\n",
    "                    load = max(load_values)\n",
    "                elif load_scenario == \"average_load\":\n",
    "                    load = sum(load_values) / len(load_values)\n",
    "                \n",
    "                # Distribute load along the path\n",
    "                path = nx.shortest_path(graph, supply, demand)\n",
    "                for i in range(len(path) - 1):\n",
    "                    edge = (path[i], path[i + 1])\n",
    "                    if edge not in edges_loads:\n",
    "                        edges_loads[edge] = {}\n",
    "                    edges_loads[edge][supply] = edges_loads[edge].get(supply, 0) + load\n",
    "    \n",
    "    # Calculate maximum load for each edge and update the graph\n",
    "    for edge in edges_loads:\n",
    "        max_load = max(edges_loads[edge].values())\n",
    "        graph.edges[edge][f\"load_{load_scenario}\"] = max_load\n",
    "        graph.edges[edge][f\"load_{load_scenario}_supplies\"] = edges_loads[edge]  # for documentation\n",
    "    \n",
    "    # Calculate mass flows\n",
    "    for edge in graph.edges:\n",
    "        if f\"load_{load_scenario}\" in graph.edges[edge]:\n",
    "            load = graph.edges[edge][f\"load_{load_scenario}\"]\n",
    "            m_flow = load / (cp * dT)\n",
    "            graph.edges[edge][f\"m_flow_{load_scenario}\"] = m_flow\n",
    "    \n",
    "    return graph\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Sizes a hydraulic network by estimating mass flows and pipe diameters.\n",
    "    \n",
    "    This function is a helper function that calls estimate_m_flow and estimate_pipe_diameter\n",
    "    in sequence to size a hydraulic network.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : UESGraph\n",
    "        The graph representing the network.\n",
    "    dT : float, optional\n",
    "        Temperature difference between supply and return in K.\n",
    "        If None, will attempt to read from demand nodes' 'dT_Network' attribute.\n",
    "    network_type : str, optional\n",
    "        Type of network, default is \"heating\".\n",
    "    demand_attribute : str, optional\n",
    "        Key for the load in the node attributes, default is \"input_heat\".\n",
    "    load_scenario : str, optional\n",
    "        Load scenario, default is \"peak_load\". Can be \"peak_load\" or \"average_load\".\n",
    "    cp : float, optional\n",
    "        Specific heat capacity of the fluid in J/(kg*K), default is 4000.\n",
    "    dp_set : float, optional\n",
    "        Specific pressure loss in Pa/m, default is 100.\n",
    "    diameters : List[float], optional\n",
    "        List of available pipe diameters in m.\n",
    "    logger : logging.Logger, optional\n",
    "        Logger to use for logging messages. If None, creates a new logger.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    graph : UESGraph\n",
    "        The input graph with additional edge attributes for mass flows and pipe diameters.\n",
    "        \n",
    "    Raises\n",
    "    ------\n",
    "    TypeError\n",
    "        If graph is not a UESGraph object.\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimate_m_flow(graph, dT,network_type, key, load_scenario = \"peak_load\")\n",
    "import networkx as nx\n",
    "\n",
    "network_type = \"heating\"\n",
    "load_scenario = \"peak_load\"\n",
    "key = \"input_heat\"\n",
    "demands = []\n",
    "supplies = []\n",
    "for node in graph.nodelist_building:\n",
    "    if graph.nodes[node][f\"is_supply_{network_type}\"]:\n",
    "        supplies.append(node)\n",
    "    else:\n",
    "        demands.append(node)\n",
    "\n",
    "edges_loads = {}\n",
    "for supply in supplies:\n",
    "    for demand in demands:\n",
    "        if nx.has_path(graph,supply,demand):\n",
    "            if load_scenario == \"peak_load\":\n",
    "                load = max([abs(x) for x in graph.nodes[node][key]])\n",
    "                path = nx.shortest_path(graph,supply,demand)\n",
    "                for i in range(len(path)-1):\n",
    "                    edge = (path[i],path[i+1])\n",
    "                    if edge not in edges_loads:\n",
    "                        edges_loads[edge] = {}\n",
    "                    edges_loads[edge][supply] = edges_loads[edge].get(supply,0) + load\n",
    "   \n",
    "\n",
    "for edge in edges_loads:\n",
    "    max_load = max(edges_loads[edge].values())\n",
    "    graph.edges[edge][f\"load_{load_scenario}\"] = max_load\n",
    "    graph.edges[edge][f\"load_{load_scenario}_supplies\"] = edges_loads[edge] # just for documentation\n",
    "    \n",
    "cp = 4000\n",
    "dT = 30\n",
    "for edge in graph.edges:\n",
    "    if f\"load_{load_scenario}\" in graph.edges[edge]:\n",
    "        load = graph.edges[edge][f\"load_{load_scenario}\"]\n",
    "        m_flow = load/(cp*dT)\n",
    "        graph.edges[edge][f\"m_flow_{load_scenario}\"] = m_flow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uesgraphs_250310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
