{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uesgraphs.uesgraph import UESGraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "json = r\"D:\\rka-lko\\git\\uesgraphs\\workspace\\e11\\inputs\\test_modelgen\\Ibpsa\\nodes.json\"\n",
    "json = r\"D:\\rka-lko\\git\\uesgraphs\\workspace\\e11\\inputs\\test_modelgen\\Pinola\\nodes.json\"\n",
    "\n",
    "graph = UESGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read nodes...\n",
      "******\n",
      " input_ids were {'buildings': None, 'nodes': '24f91801-215e-4b3d-9426-4ec51de13368', 'pipes': None, 'supplies': None}\n",
      "...finished\n"
     ]
    }
   ],
   "source": [
    "graph.from_json(path=json,network_type=\"heating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uesgraphs.systemmodels.utilities as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph2 = ut.estimate_m_flow_nominal(graph,30,\"heating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimate_m_flow(graph, dT,network_type, key, load_scenario = \"peak_load\")\n",
    "import networkx as nx\n",
    "\n",
    "network_type = \"heating\"\n",
    "load_scenario = \"peak_load\"\n",
    "key = \"input_heat\"\n",
    "demands = []\n",
    "supplies = []\n",
    "for node in graph.nodelist_building:\n",
    "    if graph.nodes[node][f\"is_supply_{network_type}\"]:\n",
    "        supplies.append(node)\n",
    "    else:\n",
    "        demands.append(node)\n",
    "\n",
    "edges_loads = {}\n",
    "for supply in supplies:\n",
    "    for demand in demands:\n",
    "        if nx.has_path(graph,supply,demand):\n",
    "            if load_scenario == \"peak_load\":\n",
    "                load = max([abs(x) for x in graph.nodes[node][key]])\n",
    "                path = nx.shortest_path(graph,supply,demand)\n",
    "                for i in range(len(path)-1):\n",
    "                    edge = (path[i],path[i+1])\n",
    "                    if edge not in edges_loads:\n",
    "                        edges_loads[edge] = {}\n",
    "                    edges_loads[edge][supply] = edges_loads[edge].get(supply,0) + load\n",
    "   \n",
    "\n",
    "for edge in edges_loads:\n",
    "    max_load = max(edges_loads[edge].values())\n",
    "    graph.edges[edge][f\"load_{load_scenario}\"] = max_load\n",
    "    graph.edges[edge][f\"load_{load_scenario}_supplies\"] = edges_loads[edge] # just for documentation\n",
    "    \n",
    "cp = 4000\n",
    "dT = 30\n",
    "for edge in graph.edges:\n",
    "    if f\"load_{load_scenario}\" in graph.edges[edge]:\n",
    "        load = graph.edges[edge][f\"load_{load_scenario}\"]\n",
    "        m_flow = load/(cp*dT)\n",
    "        graph.edges[edge][f\"m_flow_{load_scenario}\"] = m_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1006, 1007, 1008]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.nodelists_heating[\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3 demand nodes using default dT (30K): [1003, 1004, 1005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supplies: {1001, 1002}\n",
      "Demands: {1003: 0.10376102097497916, 1004: 0.03638585716480446, 1005: 0.016100928590107144}\n",
      "Supply edge flows: {1001: {(1001, 1006): 0.15624780672989078, (1006, 1003): 0.10376102097497916, (1006, 1007): 0.03638585716480446, (1007, 1004): 0.03638585716480446, (1006, 1008): 0.016100928590107144, (1008, 1005): 0.016100928590107144}, 1002: {(1002, 1008): 0.15624780672989078, (1008, 1006): 0.10376102097497916, (1006, 1003): 0.10376102097497916, (1008, 1007): 0.03638585716480446, (1007, 1004): 0.03638585716480446, (1008, 1005): 0.016100928590107144}}\n"
     ]
    }
   ],
   "source": [
    "paths = estimate_m_flow_demand_based(graph,default_dT=30,network_type=\"heating\",load_scenario=\"average_load\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logfile findable here: C:\\Users\\rka-lko\\AppData\\Local\\Temp\\hydronic_network_sizing_20250522_165027.log\n"
     ]
    }
   ],
   "source": [
    " \n",
    "flow_logger = set_up_logger(\n",
    "    name=\"hydronic_network_sizing\",\n",
    "    #log_dir=\"./logs\",  # Optional: specify custom directory\n",
    "    level=logging.DEBUG  # INFO level captures all important steps\n",
    ")\n",
    "\n",
    "# Use the logger in your mass flow estimation\n",
    "updated_graph = estimate_m_flow_demand_based(\n",
    "    graph=graph,\n",
    "    network_type=\"heating\",\n",
    "    demand_attribute=\"input_heat\",\n",
    "    load_scenario=\"peak_load\",\n",
    "    cp=4000,\n",
    "    dT_attribute=\"dT_design\",\n",
    "    logger=flow_logger  # Pass your file logger here\n",
    ")\n",
    "\n",
    "flow_logger.info(\"Mass flow estimation completed successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeView((1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001 1006 with 0.46651598954 m3/h\n",
      "1002 1008 with 0.46651598954 m3/h\n",
      "1003 1006 with 0.0 m3/h\n",
      "1004 1007 with 0.0 m3/h\n",
      "1005 1008 with 0.0 m3/h\n",
      "1006 1007 with 0.11610600000000001 m3/h\n",
      "1006 1008 with 0.161084 m3/h\n",
      "1007 1008 with 0.0 m3/h\n"
     ]
    }
   ],
   "source": [
    "edges = list(updated_graph.edges)\n",
    "for edge in edges:\n",
    "    print(f\"{edge[0]} {edge[1]} with {updated_graph.edges[edge][\"m_flow_peak_load\"]} m3/h\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "def set_up_logger(name, log_dir=None, level=int(logging.INFO)):  # Changed to INFO for more details\n",
    "    \"\"\"\n",
    "    Set up a file-based logger with timestamp and detailed formatting.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    name : str\n",
    "        Logger name, used for log file naming\n",
    "    log_dir : str, optional\n",
    "        Directory for log files. If None, uses system temp directory\n",
    "    level : int, optional\n",
    "        Logging level (default: INFO for detailed mass flow logging)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    logging.Logger\n",
    "        Configured logger instance writing to timestamped file\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(level)\n",
    "    \n",
    "    # Determine log directory\n",
    "    if log_dir is None:\n",
    "        log_dir = tempfile.gettempdir()\n",
    "    \n",
    "    # Create timestamped log file\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    log_file = os.path.join(log_dir, f\"{name}_{timestamp}.log\")\n",
    "    print(f\"Logfile findable here: {log_file}\")\n",
    "    \n",
    "    # Configure file handler with detailed formatting\n",
    "    handler = logging.FileHandler(log_file)\n",
    "    formatter = logging.Formatter(\n",
    "        '%(asctime)s - %(name)s - [%(filename)s:%(lineno)d] - %(levelname)s - %(message)s'\n",
    "    )\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    \n",
    "    return logger\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "from typing import Any, Dict, List, Optional, Set, Tuple\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "def estimate_m_flow_demand_based(\n",
    "    graph: Any,\n",
    "    network_type: str = \"heating\",\n",
    "    demand_attribute: str = \"input_heat\",\n",
    "    load_scenario: str = \"peak_load\",\n",
    "    cp: float = 4000,\n",
    "    dT_attribute: str = \"dT_Network\",\n",
    "    logger: Optional[logging.Logger] = None\n",
    ") -> Any:\n",
    "    \"\"\"\n",
    "    Estimates mass flow for each edge by calculating flows at demand nodes and propagating backwards.\n",
    "    \n",
    "    This function implements a physically correct approach where mass flows are calculated\n",
    "    at each demand node based on their specific load and temperature difference, then\n",
    "    aggregated backwards through the network following mass conservation principles.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : UESGraph or nx.Graph\n",
    "        The graph representing the network with nodelist_building attribute.\n",
    "    network_type : str, optional\n",
    "        Type of network, default is \"heating\". Must be \"heating\" or \"cooling\".\n",
    "    demand_attribute : str, optional\n",
    "        Attribute name containing load values in demand nodes, default is \"input_heat\".\n",
    "    load_scenario : str, optional\n",
    "        Load scenario for calculation, default is \"peak_load\".\n",
    "        Options: \"peak_load\" (maximum value) or \"average_load\" (mean value).\n",
    "    cp : float, optional\n",
    "        Specific heat capacity of the fluid in J/(kg*K), default is 4000.\n",
    "    dT_attribute : str\n",
    "        Node attribute name for temperature difference values in Kelvin.\n",
    "        Must be present in all demand nodes with positive numeric values.\n",
    "        Used for individual mass flow calculations at each demand node.\n",
    "    logger : logging.Logger, optional\n",
    "        Logger instance for logging messages. If None, creates a default logger.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    graph : UESGraph or nx.Graph\n",
    "        Input graph with additional edge attributes:\n",
    "        - m_flow_{load_scenario}: Mass flow rate in kg/s for each edge\n",
    "        - contributing_demands_{load_scenario}: List of demand nodes contributing to edge flow\n",
    "        - supply_attribution_{load_scenario}: Dictionary showing which supply serves which demands\n",
    "        \n",
    "    Raises\n",
    "    ------\n",
    "    TypeError\n",
    "        If graph does not have required nodelist_building attribute.\n",
    "    ValueError\n",
    "        If network_type or load_scenario parameters are invalid.\n",
    "        If no supply or demand nodes are found.\n",
    "        If required node attributes are missing.\n",
    "    \"\"\"\n",
    "    # Initialize logger\n",
    "    if logger is None:\n",
    "        logger = logging.getLogger(__name__)\n",
    "    \n",
    "    # Validate input parameters\n",
    "    _validate_parameters(graph, network_type, load_scenario, demand_attribute)\n",
    "    \n",
    "    # Step 1: Identify and categorize nodes\n",
    "    supply_nodes, demand_nodes = _identify_network_nodes(\n",
    "        graph, network_type, demand_attribute, logger\n",
    "    )\n",
    "    \n",
    "    # Step 2: Calculate mass flows at demand nodes\n",
    "    demand_mass_flows = _calculate_demand_mass_flows(\n",
    "        graph, demand_nodes, demand_attribute, load_scenario, cp, dT_attribute, logger\n",
    "    )\n",
    "    \n",
    "    # Step 3: Build supply-to-demand flow paths\n",
    "    supply_demand_paths = _build_flow_paths(\n",
    "        graph, supply_nodes, demand_nodes, logger\n",
    "    )\n",
    "    \n",
    "   # Step 4: Aggregate mass flows on edges using maximum principle\n",
    "    _aggregate_edge_flows_robust(\n",
    "        graph, supply_demand_paths, demand_mass_flows, load_scenario, logger\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Successfully calculated mass flows for {len(graph.edges)} edges \"\n",
    "               f\"using demand-based approach with {load_scenario} scenario\")\n",
    "    \n",
    "    return graph\n",
    "\n",
    "\n",
    "def _validate_parameters(\n",
    "    graph: Any, \n",
    "    network_type: str, \n",
    "    load_scenario: str, \n",
    "    demand_attribute: str\n",
    ") -> None:\n",
    "    \"\"\"Validate input parameters for the mass flow estimation function.\"\"\"\n",
    "    if not hasattr(graph, \"nodelist_building\"):\n",
    "        raise TypeError(\"Graph must be a UESGraph object with nodelist_building attribute\")\n",
    "    \n",
    "    if network_type not in [\"heating\", \"cooling\"]:\n",
    "        raise ValueError(\"network_type must be 'heating' or 'cooling'\")\n",
    "    \n",
    "    if load_scenario not in [\"peak_load\", \"average_load\"]:\n",
    "        raise ValueError(\"load_scenario must be 'peak_load' or 'average_load'\")\n",
    "\n",
    "\n",
    "def _identify_network_nodes(\n",
    "    graph: Any, \n",
    "    network_type: str, \n",
    "    demand_attribute: str, \n",
    "    logger: logging.Logger\n",
    ") -> Tuple[List[Any], List[Any]]:\n",
    "    \"\"\"\n",
    "    Identify and categorize supply and demand nodes in the network.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (supply_nodes, demand_nodes) - Lists of supply and demand node identifiers\n",
    "    \"\"\"\n",
    "    supply_nodes = []\n",
    "    demand_nodes = []\n",
    "    supply_attr = f\"is_supply_{network_type}\"\n",
    "    \n",
    "    for node in graph.nodelist_building:\n",
    "        # Check for required supply attribute\n",
    "        if supply_attr not in graph.nodes[node]:\n",
    "            raise ValueError(f\"Node {node} missing required attribute '{supply_attr}'\")\n",
    "        \n",
    "        if graph.nodes[node][supply_attr]:\n",
    "            supply_nodes.append(node)\n",
    "        else:\n",
    "            # Validate demand node has required load attribute\n",
    "            if demand_attribute not in graph.nodes[node]:\n",
    "                raise ValueError(f\"Demand node {node} missing required attribute '{demand_attribute}'\")\n",
    "            demand_nodes.append(node)\n",
    "    \n",
    "    # Ensure we have both supply and demand nodes\n",
    "    if not supply_nodes:\n",
    "        raise ValueError(f\"No supply nodes found for network type '{network_type}'\")\n",
    "    if not demand_nodes:\n",
    "        raise ValueError(f\"No demand nodes found for network type '{network_type}'\")\n",
    "    \n",
    "    logger.info(f\"Identified {len(supply_nodes)} supply nodes and {len(demand_nodes)} demand nodes\")\n",
    "    return supply_nodes, demand_nodes\n",
    "\n",
    "\n",
    "def _calculate_demand_mass_flows(\n",
    "    graph: Any,\n",
    "    demand_nodes: List[Any],\n",
    "    demand_attribute: str,\n",
    "    load_scenario: str,\n",
    "    cp: float,\n",
    "    dT_attribute: str,\n",
    "    logger: logging.Logger\n",
    ") -> Dict[Any, float]:\n",
    "    \"\"\"\n",
    "    Calculate mass flow requirements at each demand node.\n",
    "    \n",
    "    This function processes each demand node individually, calculating the required\n",
    "    mass flow based on the node's load and temperature difference (dT).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : UESGraph or nx.Graph\n",
    "        Network graph containing node data\n",
    "    demand_nodes : List[Any]\n",
    "        List of demand node identifiers\n",
    "    demand_attribute : str\n",
    "        Attribute name containing load values\n",
    "    load_scenario : str\n",
    "        Either \"peak_load\" or \"average_load\"\n",
    "    cp : float\n",
    "        Specific heat capacity in J/(kg*K)\n",
    "    dT_attribute : str\n",
    "        Node attribute name for temperature difference values in Kelvin.\n",
    "        Must be present in all demand nodes with positive numeric values.\n",
    "        Used for individual mass flow calculations at each demand node.\n",
    "    logger : logging.Logger\n",
    "        Logger for status messages\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Dict[Any, float]\n",
    "        Dictionary mapping demand node identifiers to their mass flow requirements in kg/s\n",
    "    \"\"\"\n",
    "    \n",
    "    for demand_node in demand_nodes:\n",
    "        if dT_attribute not in graph.nodes[demand_node]:\n",
    "            # Get available attributes for better error message\n",
    "            available_attrs = list(graph.nodes[demand_node].keys())\n",
    "            dT_related_attrs = [attr for attr in available_attrs if 'dT' in attr or 'delta' in attr.lower() or 'temp' in attr.lower()]\n",
    "\n",
    "            error_msg = (\n",
    "                f\"Demand node '{demand_node}' is missing the required temperature difference attribute '{dT_attribute}'. \"\n",
    "                f\"This attribute must contain the temperature difference (dT) in Kelvin between supply and return flow \"\n",
    "                f\"for mass flow calculation (formula: m_flow = thermal_load / (cp * dT)).\\n\\n\"\n",
    "                f\"To fix this issue:\\n\"\n",
    "                f\"1. Add '{dT_attribute}' attribute to node '{demand_node}' with a numeric value in Kelvin\\n, like with graph.nodes[{demand_node}]['{dT_attribute}'] = 30\\n\"\n",
    "                f\"2. Or specify a different attribute name using the 'dT_attribute' parameter\\n\"\n",
    "            )\n",
    "\n",
    "            if dT_related_attrs:\n",
    "                error_msg += f\"\\nConsider using: dT_attribute='{dT_related_attrs[0]}' if appropriate, when calling method\"\n",
    "\n",
    "            raise ValueError(error_msg)\n",
    "        \n",
    "    demand_mass_flows = {}\n",
    "    \n",
    "    for demand_node in demand_nodes:\n",
    "        # Extract load values from node attribute\n",
    "        load_values = graph.nodes[demand_node][demand_attribute]\n",
    "        \n",
    "        # Handle both single values and lists\n",
    "        if isinstance(load_values, (int, float)):\n",
    "            load_values = [load_values]\n",
    "        \n",
    "        # Convert to absolute values for calculation\n",
    "        abs_load_values = [abs(x) for x in load_values]\n",
    "        \n",
    "        # Calculate load based on scenario\n",
    "        if load_scenario == \"peak_load\":\n",
    "            load = max(abs_load_values)\n",
    "        elif load_scenario == \"average_load\":\n",
    "            load = sum(abs_load_values) / len(abs_load_values)\n",
    "        \n",
    "        # Get node-specific temperature difference\n",
    "        node_dT = graph.nodes[demand_node][dT_attribute]\n",
    "        # Validate dT value\n",
    "        if not isinstance(node_dT, (int, float)) or node_dT <= 0:\n",
    "            raise ValueError(\n",
    "                f\"Temperature difference (dT) for demand node '{demand_node}' must be a positive number, \"\n",
    "                f\"got {node_dT} (type: {type(node_dT).__name__})\"\n",
    "            )\n",
    "\n",
    "        # Calculate mass flow: m_flow = Q / (cp * dT)\n",
    "        mass_flow = load / (cp * node_dT)\n",
    "        demand_mass_flows[demand_node] = mass_flow\n",
    "        \n",
    "        logger.debug(f\"Demand node {demand_node}: load={load:.2f}W, dT={node_dT}K, \"\n",
    "                    f\"m_flow={mass_flow:.6f}kg/s\")\n",
    "    \n",
    "    \n",
    "    total_demand_flow = sum(demand_mass_flows.values())\n",
    "    logger.info(f\"Calculated mass flows for {len(demand_nodes)} demand nodes, \"\n",
    "               f\"total demand: {total_demand_flow:.6f} kg/s\")\n",
    "    \n",
    "    return demand_mass_flows\n",
    "\n",
    "def _build_flow_paths(\n",
    "    graph: Any,\n",
    "    supply_nodes: List[Any],\n",
    "    demand_nodes: List[Any],\n",
    "    logger: logging.Logger\n",
    ") -> Dict[Tuple[Any, Any], List[Tuple[Any, Any]]]:\n",
    "    \"\"\"\n",
    "    Build flow paths from each supply node to reachable demand nodes.\n",
    "    \n",
    "    This function identifies all supply-demand pairs that are connected and\n",
    "    determines the shortest path between them, converting paths to edge lists.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : UESGraph or nx.Graph\n",
    "        Network graph\n",
    "    supply_nodes : List[Any]\n",
    "        List of supply node identifiers\n",
    "    demand_nodes : List[Any]\n",
    "        List of demand node identifiers\n",
    "    logger : logging.Logger\n",
    "        Logger for status messages\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Dict[Tuple[Any, Any], List[Tuple[Any, Any]]]\n",
    "        Dictionary mapping (supply, demand) tuples to lists of edges in the flow path\n",
    "    \"\"\"\n",
    "    supply_demand_paths = {}\n",
    "    unreachable_demands = set(demand_nodes)  # Track which demands are reachable\n",
    "    \n",
    "    for supply in supply_nodes:\n",
    "        reachable_from_this_supply = []\n",
    "        \n",
    "        for demand in demand_nodes:\n",
    "            try:\n",
    "                if nx.has_path(graph, supply, demand):\n",
    "                    # Calculate shortest path and convert to edge list\n",
    "                    node_path = nx.shortest_path(graph, supply, demand)\n",
    "                    edge_path = [(node_path[i], node_path[i + 1]) \n",
    "                                for i in range(len(node_path) - 1)]\n",
    "                    \n",
    "                    supply_demand_paths[(supply, demand)] = edge_path\n",
    "                    reachable_from_this_supply.append(demand)\n",
    "                    \n",
    "                    # Remove from unreachable set\n",
    "                    unreachable_demands.discard(demand)\n",
    "                    \n",
    "            except nx.NetworkXNoPath:\n",
    "                # Explicitly handle case where no path exists\n",
    "                continue\n",
    "        \n",
    "        logger.debug(f\"Supply {supply} can reach {len(reachable_from_this_supply)} demands: \"\n",
    "                    f\"{reachable_from_this_supply}\")\n",
    "    \n",
    "    # Log summary information\n",
    "    total_paths = len(supply_demand_paths)\n",
    "    logger.info(f\"Built {total_paths} supply-to-demand flow paths\")\n",
    "    \n",
    "    if unreachable_demands:\n",
    "        logger.warning(f\"Unreachable demand nodes found: {list(unreachable_demands)}\")\n",
    "    \n",
    "    return supply_demand_paths\n",
    "\n",
    "def _aggregate_edge_flows_robust(\n",
    "    graph: Any,\n",
    "    supply_demand_paths: Dict[Tuple[Any, Any], List[Tuple[Any, Any]]],\n",
    "    demand_mass_flows: Dict[Any, float],\n",
    "    load_scenario: str,\n",
    "    logger: logging.Logger\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Aggregate mass flows on edges using a robust supply-based approach with maximum flow principle.\n",
    "    \n",
    "    This function implements a two-stage aggregation process:\n",
    "    1. For each supply node, calculate cumulative flows on all edges serving its connected demands\n",
    "    2. Apply maximum flow principle when multiple supplies can serve the same edge\n",
    "    \n",
    "    This approach ensures robust network sizing where each edge is dimensioned for the worst-case\n",
    "    scenario among all possible supply configurations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : UESGraph or nx.Graph\n",
    "        Network graph to be modified with calculated flow data\n",
    "    supply_demand_paths : Dict[Tuple[Any, Any], List[Tuple[Any, Any]]]\n",
    "        Mapping of (supply, demand) pairs to their corresponding edge paths\n",
    "    demand_mass_flows : Dict[Any, float]\n",
    "        Mass flow requirements for each demand node in kg/s\n",
    "    load_scenario : str\n",
    "        Load scenario identifier used for attribute naming in the graph\n",
    "    logger : logging.Logger\n",
    "        Logger instance for progress and summary information\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting robust edge flow aggregation using supply-based approach\")\n",
    "    \n",
    "    # Initialize data structures for supply-based flow tracking\n",
    "    supply_edge_flows = {}  # {supply_node: {edge: accumulated_flow}}\n",
    "    edge_contributing_demands = {}  # {edge: set_of_demand_nodes}\n",
    "    supply_attribution = {}  # {demand_node: supply_node}\n",
    "    \n",
    "    # Step 1: Group supply-demand paths by supply node for separate processing\n",
    "    supplies = set(supply for supply, demand in supply_demand_paths.keys())\n",
    "    logger.info(f\"Processing flows for {len(supplies)} supply nodes\")\n",
    "    \n",
    "    # Step 2: Calculate aggregated flows for each supply node independently\n",
    "    for supply in supplies:\n",
    "        supply_edge_flows[supply] = {}\n",
    "        demands_served = []\n",
    "        \n",
    "        logger.debug(f\"Processing supply node: {supply}\")\n",
    "        \n",
    "        # Process all demand nodes served by this supply\n",
    "        for (sup, demand), edge_path in supply_demand_paths.items():\n",
    "            if sup == supply:\n",
    "                demand_flow = demand_mass_flows[demand]\n",
    "                demands_served.append(demand)\n",
    "                \n",
    "                # Record supply attribution for this demand\n",
    "                supply_attribution[demand] = supply\n",
    "                \n",
    "                # Accumulate demand flow along the entire path to this demand\n",
    "                for edge in edge_path:\n",
    "                    # Add flow to supply-specific edge flow tracking\n",
    "                    if edge in supply_edge_flows[supply]:\n",
    "                        supply_edge_flows[supply][edge] += demand_flow\n",
    "                    else:\n",
    "                        supply_edge_flows[supply][edge] = demand_flow\n",
    "                    \n",
    "                    # Track which demands contribute to each edge for documentation\n",
    "                    if edge not in edge_contributing_demands:\n",
    "                        edge_contributing_demands[edge] = set()\n",
    "                    edge_contributing_demands[edge].add(demand)\n",
    "        \n",
    "        total_supply_flow = sum(demand_mass_flows[d] for d in demands_served)\n",
    "        logger.debug(f\"Supply {supply}: serves {len(demands_served)} demands, \"\n",
    "                    f\"total flow = {total_supply_flow:.6f} kg/s\")\n",
    "    \n",
    "    logger.debug(f\"Identified flows: {supply_edge_flows}\")\n",
    "\n",
    "    # Step 3: Apply maximum flow principle across all supplies for robust sizing\n",
    "    logger.info(\"Applying maximum flow principle across supplies for robust edge sizing\")\n",
    "    final_edge_flows = {}\n",
    "    supply_conflicts = {}  # Track edges with multiple supply options\n",
    "    \n",
    "    for supply, edge_flows in supply_edge_flows.items():\n",
    "        for edge, flow in edge_flows.items():\n",
    "            # Normalize edge representation for consistent dictionary access\n",
    "            normalized_edge = __normalize_edge(edge)\n",
    "            logger.debug(f\"Processing edge {edge} with flow {flow:.6f} kg/s from supply {supply}\")\n",
    "            if normalized_edge  in final_edge_flows:\n",
    "                # Multiple supplies can serve this edge - apply maximum principle\n",
    "                if normalized_edge  not in supply_conflicts:\n",
    "                    supply_conflicts[normalized_edge ] = []\n",
    "                supply_conflicts[normalized_edge ].append((supply, flow))\n",
    "                \n",
    "                # Update to maximum flow value for robust design\n",
    "                final_edge_flows[normalized_edge ] = max(final_edge_flows[normalized_edge ], flow)\n",
    "            else:\n",
    "                # First supply to use this edge\n",
    "                final_edge_flows[normalized_edge ] = flow\n",
    "    \n",
    "    # Log information about supply conflicts and robust sizing decisions\n",
    "    if supply_conflicts:\n",
    "        logger.info(f\"Applied maximum flow principle to {len(supply_conflicts)} edges \"\n",
    "                   f\"with multiple supply options\")\n",
    "        for edge, conflicts in supply_conflicts.items():\n",
    "            flows = [f\"{supply}: {flow:.6f}\" for supply, flow in conflicts]\n",
    "            max_flow = final_edge_flows[edge]\n",
    "            logger.debug(f\"Edge {edge} - Supplies: [{', '.join(flows)}] â†’ \"\n",
    "                        f\"Selected: {max_flow:.6f} kg/s\")\n",
    "    \n",
    "    # Step 4: Apply calculated flows to all graph edges\n",
    "    edges_with_flow = 0\n",
    "    edges_without_flow = 0\n",
    "    \n",
    "    for edge in graph.edges:\n",
    "        # Normalize the current graph edge for dictionary lookup\n",
    "        normalized_edge = __normalize_edge(edge)\n",
    "        if normalized_edge in final_edge_flows:\n",
    "            # Set mass flow attribute for edges with calculated flows\n",
    "            graph.edges[normalized_edge][f\"m_flow_{load_scenario}\"] = final_edge_flows[normalized_edge]\n",
    "            \n",
    "            # Document which demands contribute to this edge's flow\n",
    "            graph.edges[normalized_edge][f\"contributing_demands_{load_scenario}\"] = list(\n",
    "                edge_contributing_demands[normalized_edge]\n",
    "            )\n",
    "            \n",
    "            edges_with_flow += 1\n",
    "        else:\n",
    "            # Initialize edges without flow (not part of any supply-demand path)\n",
    "            graph.edges[normalized_edge][f\"m_flow_{load_scenario}\"] = 0.0\n",
    "            graph.edges[normalized_edge][f\"contributing_demands_{load_scenario}\"] = []\n",
    "            edges_without_flow += 1\n",
    "    \n",
    "    # Step 5: Store supply attribution information at graph level for reference\n",
    "    graph.graph[f\"supply_attribution_{load_scenario}\"] = supply_attribution\n",
    "    \n",
    "    # Step 6: Calculate and log comprehensive summary statistics\n",
    "    total_demand_flow = sum(demand_mass_flows.values())\n",
    "    active_edges_flow = sum(final_edge_flows.values()) if final_edge_flows else 0.0\n",
    "    \n",
    "    logger.info(f\"Flow aggregation completed successfully:\")\n",
    "    logger.info(f\"  - Total demand flow: {total_demand_flow:.6f} kg/s\")\n",
    "    logger.info(f\"  - Edges with flow: {edges_with_flow}/{len(graph.edges)}\")\n",
    "    logger.info(f\"  - Edges without flow: {edges_without_flow}\")\n",
    "    logger.info(f\"  - Supply-demand pairs processed: {len(supply_demand_paths)}\")\n",
    "    \n",
    "    # Log flow distribution statistics for active edges\n",
    "    if final_edge_flows:\n",
    "        max_edge_flow = max(final_edge_flows.values())\n",
    "        min_edge_flow = min(final_edge_flows.values())\n",
    "        avg_edge_flow = sum(final_edge_flows.values()) / len(final_edge_flows)\n",
    "        \n",
    "        logger.info(f\"Active edge flow statistics:\")\n",
    "        logger.info(f\"  - Maximum edge flow: {max_edge_flow:.6f} kg/s\")\n",
    "        logger.info(f\"  - Minimum edge flow: {min_edge_flow:.6f} kg/s\")\n",
    "        logger.info(f\"  - Average edge flow: {avg_edge_flow:.6f} kg/s\")\n",
    "    \n",
    "    logger.info(\"Robust edge flow aggregation completed successfully\")\n",
    "\n",
    "def __normalize_edge(edge):\n",
    "    \"\"\"\n",
    "    Normalize edge tuple to consistent order for undirected graph operations.\n",
    "    \n",
    "    This function ensures that edges (A, B) and (B, A) are treated as the same edge\n",
    "    by always returning the tuple with the smaller node ID first.\n",
    "    \n",
    "    Args:\n",
    "        edge (tuple): Edge as (node1, node2)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Normalized edge as (min_node, max_node)\n",
    "    \"\"\"\n",
    "    return tuple(sorted(edge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "from typing import Any, List, Optional, Dict\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "def estimate_m_flow(\n",
    "    graph: Any,\n",
    "    dT: Optional[float] = None,\n",
    "    network_type: str = \"heating\",\n",
    "    demand_attribute: str = \"input_heat\",\n",
    "    load_scenario: str = \"peak_load\",\n",
    "    cp: float = 4000,\n",
    "    logger: Optional[logging.Logger] = None\n",
    ") -> Any:\n",
    "    \"\"\"\n",
    "    Estimates the mass flow for each edge in the graph based on building loads.\n",
    "    \n",
    "    This function calculates the maximum load for each edge in the graph based on\n",
    "    the shortest path from producer to consumer nodes and then calculates the\n",
    "    mass flow for each edge based on the maximum load.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : UESGraph or nx.Graph\n",
    "        The graph representing the network.\n",
    "    dT : float, optional\n",
    "        Temperature difference between supply and return in K.\n",
    "        If None, will attempt to read from demand nodes' 'dT_Network' attribute.\n",
    "    network_type : str, optional\n",
    "        Type of network, default is \"heating\".\n",
    "    demand_attribute : str, optional\n",
    "        Key for the load in the node attributes, default is \"input_heat\".\n",
    "    load_scenario : str, optional\n",
    "        Load scenario, default is \"peak_load\". Can be \"peak_load\" or \"average_load\".\n",
    "    cp : float, optional\n",
    "        Specific heat capacity of the fluid in J/(kg*K), default is 4000.\n",
    "    logger : logging.Logger, optional\n",
    "        Logger to use for logging messages. If None, creates a new logger.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    graph : UESGraph or nx.Graph\n",
    "        The input graph with additional edge attributes:\n",
    "        - load_{load_scenario}: Maximum load for the edge\n",
    "        - load_{load_scenario}_supplies: Dictionary with loads for each producer\n",
    "        - m_flow_{load_scenario}: Mass flow for the edge\n",
    "        \n",
    "    Raises\n",
    "    ------\n",
    "    TypeError\n",
    "        If graph is not a UESGraph object with nodelist_building attribute.\n",
    "    ValueError\n",
    "        If network_type is not 'heating' or 'cooling'.\n",
    "        If load_scenario is not 'peak_load' or 'average_load'.\n",
    "        If no producer or consumer nodes are found.\n",
    "        If dT is not provided and cannot be determined from node attributes.\n",
    "    \"\"\"\n",
    "    # Set up logger\n",
    "    if logger is None:\n",
    "        logger = logging.getLogger(__name__)\n",
    "    \n",
    "    # Validate parameters\n",
    "    if not hasattr(graph, \"nodelist_building\"):\n",
    "        raise TypeError(\"graph must be a UESGraph object with nodelist_building attribute\")\n",
    "    \n",
    "    if network_type not in [\"heating\", \"cooling\"]:\n",
    "        raise ValueError(\"network_type must be 'heating' or 'cooling'\")\n",
    "    \n",
    "    if load_scenario not in [\"peak_load\", \"average_load\"]:\n",
    "        raise ValueError(\"load_scenario must be 'peak_load' or 'average_load'\")\n",
    "    \n",
    "    # Find consumer and producer nodes\n",
    "    demands = []\n",
    "    supplies = []\n",
    "    dT_node_values = {}  # Dictionary to store dT values for each demand node\n",
    "\n",
    "    for node in graph.nodelist_building:\n",
    "        supply_attr = f\"is_supply_{network_type}\"\n",
    "        if supply_attr not in graph.nodes[node]:\n",
    "            raise ValueError(f\"Node {node} does not have attribute '{supply_attr}'\")\n",
    "        \n",
    "        if graph.nodes[node][supply_attr]:\n",
    "            supplies.append(node)\n",
    "        else:\n",
    "            if demand_attribute not in graph.nodes[node]:\n",
    "                raise ValueError(f\"Node {node} does not have attribute '{demand_attribute}'\")\n",
    "            demands.append(node)\n",
    "            \n",
    "            # Collect dT values from demand nodes if available\n",
    "            if dT is None and 'dT_Network' in graph.nodes[node]:\n",
    "                dT_node_values[node] = graph.nodes[node]['dT_Network']\n",
    "    \n",
    "    if not supplies:\n",
    "        raise ValueError(f\"No producer nodes found for network type '{network_type}'\")\n",
    "    \n",
    "    if not demands:\n",
    "        raise ValueError(f\"No consumer nodes found for network type '{network_type}'\")\n",
    "    \n",
    "    # Determine global dT or flag for node-specific usage\n",
    "    use_node_specific_dT = False\n",
    "\n",
    "    # Determine temperature difference (dT)\n",
    "    if dT is not None:\n",
    "        # Use the explicitly provided dT parameter\n",
    "        logger.info(f\"Using provided dT value: {dT} K\")\n",
    "    elif dT_node_values:\n",
    "        # We have dT values from nodes, but need to decide how to use them\n",
    "        if len(set(dT_node_values.values())) == 1:\n",
    "             # All nodes have the same dT value, so use that\n",
    "            dT = next(iter(dT_node_values.values()))\n",
    "            logger.info(f\"Using uniform dT={dT} K from all demand nodes\")\n",
    "        elif  len(dT_node_values) == len(demands):\n",
    "            use_node_specific_dT = True\n",
    "            # Nodes have different dT values - we'll use node-specific values later\n",
    "            logger.info(f\"Using node-specific dT values from demand nodes\")\n",
    "        else:\n",
    "            # Some nodes have dT values, but not all - use the average\n",
    "            dT = sum(dT_node_values.values()) / len(dT_node_values)\n",
    "            logger.info(f\"Using average dT={dT} K from demand nodes\")\n",
    "           \n",
    "    elif hasattr(graph, \"graph\") and \"dT_design\" in graph.graph:\n",
    "        # Fallback to deprecated attribute\n",
    "        dT = graph.graph[\"dT_design\"]\n",
    "        warnings.warn(\n",
    "            \"'dT_design' attribute is deprecated. Use 'dT_Network' in demand nodes instead.\",\n",
    "            DeprecationWarning\n",
    "        )\n",
    "        logger.warning(f\"Using deprecated 'dT_design' attribute: {dT} K\")\n",
    "    else:\n",
    "        # Last resort: default value with warning\n",
    "        dT = 20.0  # Common default for heating networks\n",
    "        warnings.warn(\n",
    "            f\"No dT specified. Using default value of {dT} K. \"\n",
    "            \"Specify dT explicitly or add 'dT_Network' to demand nodes.\",\n",
    "            UserWarning\n",
    "        )\n",
    "        logger.warning(f\"No dT specified. Using default value of {dT} K\")\n",
    "    \n",
    "    logger.info(f\"Estimating mass flows for {network_type} network with {load_scenario} scenario (dT={dT}K)\")\n",
    "    \n",
    "    # Calculate loads for edges\n",
    "    edges_loads = {}\n",
    "    \n",
    "    for supply in supplies:\n",
    "        for demand in demands:\n",
    "            if nx.has_path(graph, supply, demand):\n",
    "                # Calculate load for the consumer node\n",
    "                load_values = [abs(x) for x in graph.nodes[demand][demand_attribute]]\n",
    "                \n",
    "                if load_scenario == \"peak_load\":\n",
    "                    load = max(load_values)\n",
    "                elif load_scenario == \"average_load\":\n",
    "                    load = sum(load_values) / len(load_values)\n",
    "                \n",
    "                # Distribute load along the path\n",
    "                path = nx.shortest_path(graph, supply, demand)\n",
    "                for i in range(len(path) - 1):\n",
    "                    edge = (path[i], path[i + 1])\n",
    "                    if edge not in edges_loads:\n",
    "                        edges_loads[edge] = {}\n",
    "                    edges_loads[edge][supply] = edges_loads[edge].get(supply, 0) + load\n",
    "    \n",
    "    # Calculate maximum load for each edge and update the graph\n",
    "    for edge in edges_loads:\n",
    "        max_load = max(edges_loads[edge].values())\n",
    "        graph.edges[edge][f\"load_{load_scenario}\"] = max_load\n",
    "        graph.edges[edge][f\"load_{load_scenario}_supplies\"] = edges_loads[edge]  # for documentation\n",
    "    \n",
    "    # Calculate mass flows\n",
    "    for edge in graph.edges:\n",
    "        if f\"load_{load_scenario}\" in graph.edges[edge]:\n",
    "            load = graph.edges[edge][f\"load_{load_scenario}\"]\n",
    "            m_flow = load / (cp * dT)\n",
    "            graph.edges[edge][f\"m_flow_{load_scenario}\"] = m_flow\n",
    "    \n",
    "    return graph\n",
    "\n",
    "\n",
    "def size_hydronic_network(\n",
    "    graph: Any,\n",
    "    dT: Optional[float] = None,\n",
    "    network_type: str = \"heating\",\n",
    "    demand_attribute: str = \"input_heat\",\n",
    "    load_scenario: str = \"peak_load\",\n",
    "    cp: float = 4000,\n",
    "    dp_set: float = 100,\n",
    "    diameters: Optional[List[float]] = None,\n",
    "    logger: Optional[logging.Logger] = None\n",
    ") -> Any:\n",
    "    \"\"\"\n",
    "    Sizes a hydraulic network by estimating mass flows and pipe diameters.\n",
    "    \n",
    "    This function is a helper function that calls estimate_m_flow and estimate_pipe_diameter\n",
    "    in sequence to size a hydraulic network.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : UESGraph\n",
    "        The graph representing the network.\n",
    "    dT : float, optional\n",
    "        Temperature difference between supply and return in K.\n",
    "        If None, will attempt to read from demand nodes' 'dT_Network' attribute.\n",
    "    network_type : str, optional\n",
    "        Type of network, default is \"heating\".\n",
    "    demand_attribute : str, optional\n",
    "        Key for the load in the node attributes, default is \"input_heat\".\n",
    "    load_scenario : str, optional\n",
    "        Load scenario, default is \"peak_load\". Can be \"peak_load\" or \"average_load\".\n",
    "    cp : float, optional\n",
    "        Specific heat capacity of the fluid in J/(kg*K), default is 4000.\n",
    "    dp_set : float, optional\n",
    "        Specific pressure loss in Pa/m, default is 100.\n",
    "    diameters : List[float], optional\n",
    "        List of available pipe diameters in m.\n",
    "    logger : logging.Logger, optional\n",
    "        Logger to use for logging messages. If None, creates a new logger.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    graph : UESGraph\n",
    "        The input graph with additional edge attributes for mass flows and pipe diameters.\n",
    "        \n",
    "    Raises\n",
    "    ------\n",
    "    TypeError\n",
    "        If graph is not a UESGraph object.\n",
    "    \"\"\"\n",
    "    # Set up logger\n",
    "    if logger is None:\n",
    "        logger = logging.getLogger(__name__)\n",
    "        handler = logging.StreamHandler()\n",
    "        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "        handler.setFormatter(formatter)\n",
    "        logger.addHandler(handler)\n",
    "        logger.setLevel(logging.INFO)\n",
    "    \n",
    "    # Estimate mass flows\n",
    "    logger.info(f\"Sizing hydronic network: estimating mass flows for {network_type} network with {load_scenario} scenario\")\n",
    "    graph = estimate_m_flow(\n",
    "        graph=graph,\n",
    "        dT=dT,\n",
    "        network_type=network_type,\n",
    "        demand_attribute=demand_attribute,\n",
    "        load_scenario=load_scenario,\n",
    "        cp=cp,\n",
    "        logger=logger\n",
    "    )\n",
    "    \n",
    "    # Estimate pipe diameters\n",
    "    logger.info(f\"Sizing hydronic network: estimating pipe diameters for {network_type} network with {load_scenario} scenario\")\n",
    "    # Note: This assumes estimate_pipe_diameter is defined elsewhere\n",
    "    from ues_network_sizing import estimate_pipe_diameter  # Import only when needed\n",
    "    graph = estimate_pipe_diameter(\n",
    "        graph=graph,\n",
    "        load_scenario=load_scenario,\n",
    "        dp_set=dp_set,\n",
    "        diameters=diameters\n",
    "    )\n",
    "    \n",
    "    return graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uesgraphs_git1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
